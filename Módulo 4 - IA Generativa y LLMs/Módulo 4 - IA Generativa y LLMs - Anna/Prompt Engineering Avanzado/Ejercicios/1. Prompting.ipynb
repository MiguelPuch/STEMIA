{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e35d49f",
   "metadata": {},
   "source": [
    "# 1. Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95861c2b",
   "metadata": {},
   "source": [
    "Objetivo\n",
    "\n",
    "La ingeniería de prompts permite dotar de información adicional a un modelo generalista para obtener resultados más cercanos a lo que buscamos. Esta práctica tiene como objetivo que explores cómo diseñar prompts creativos y efectivos y cómo encadenarlos usando LangChain y la API de Gemini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e6800",
   "metadata": {},
   "source": [
    "## Parte 1: Preparación del entorno\n",
    "\n",
    "Obtén tu API key de Gemini en Google AI Studio\n",
    "\n",
    "Guarda la clave en la variable de entorno GEMINI_API_KEY.\n",
    "\n",
    "Crea un LLM básico con la siguiente configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84968c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ce8b",
   "metadata": {},
   "source": [
    "Prueba la LLM con 5 mensajes simples. Observa cómo la LLM necesita información suficiente para responder correctamente. El prompt que escribas y el contexto que proveas serán clave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3d520",
   "metadata": {},
   "source": [
    "## Parte 2: Contexto y mensajes del sistema\n",
    "\n",
    "El contexto es todo lo que el modelo sabe sobre cómo responder. Las instrucciones del sistema son fundamentales para definir estilo, tono o restricciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd01070",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Eres un historiador que habla en verso y con mal humor.\"),\n",
    "    HumanMessage(\"Explícame quién fue Alejandro Magno.\"),\n",
    "]\n",
    "\n",
    "respuesta = llm.invoke(messages)\n",
    "print(respuesta.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954adf1",
   "metadata": {},
   "source": [
    "Modifica el estilo del sistema para que mezcle buen humor y rima en sus explicaciones.\n",
    "\n",
    "Observa cómo cambia la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7020fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Parte 3: Plantillas y encadenamiento de prompts\n",
    "\n",
    "Usa ChatPromptTemplate o PromptTemplate para transformar la salida de la LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b5d71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Eres un juglar de la corte del rey Felipe IV.\n",
    "Convierte el siguiente tema en un texto creativo con bromas en castellano antiguo:\n",
    "\n",
    "Tema: {tema}\n",
    "\"\"\")\n",
    "\n",
    "cadena = prompt_template | llm\n",
    "response = cadena.invoke({\"tema\": \"Caballo\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31c151",
   "metadata": {},
   "source": [
    "1. Crea tres variaciones de tu plantilla:\n",
    "\n",
    "   - Una que transforme el texto en acertijos históricos\n",
    "\n",
    "   - Otra en cuento fantástico de máximo 150 palabras\n",
    "\n",
    "   - Otra en diálogo humorístico entre personajes históricos\n",
    "\n",
    "2. Encadena las plantillas:\n",
    "\n",
    "   - Primero genera el texto base, luego aplica la transformación en otro prompt.\n",
    "\n",
    "   - Observa cómo cambia el resultado según el encadenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07338672",
   "metadata": {},
   "source": [
    "## Parte 4: Técnicas avanzadas\n",
    "\n",
    "1. Zero-Shot\n",
    "\n",
    "Prueba generar contenido sin dar ejemplos. Observa la creatividad y limitaciones.\n",
    "\n",
    "2. Few-Shot\n",
    "\n",
    "Proporciona 5 ejemplos previos de cómo quieres que se genere el contenido.\n",
    "\n",
    "Compara con la salida de Zero-Shot.\n",
    "\n",
    "3. Chain-of-Thought\n",
    "\n",
    "Haz que la LLM explique paso a paso un concepto complejo antes de dar la respuesta final.\n",
    "\n",
    "4. Tree-of-Thoughts\n",
    "\n",
    "Explora varias posibles cadenas de razonamiento y selecciona la más coherente o creativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135672e",
   "metadata": {},
   "source": [
    "## Parte 5: Traducción y estilo\n",
    "\n",
    "Usa ChatPromptTemplate para traducir tus textos a otros idiomas manteniendo el estilo original, p. ej.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc303be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"Traduce el siguiente texto a {idioma} manteniendo su estilo humorístico\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{texto}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5c271",
   "metadata": {},
   "source": [
    "Traduce el resultado de tu plantilla a italiano, japonés o inglés antiguo manteniendo la rima o humor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6d88e",
   "metadata": {},
   "source": [
    "## Parte 6: Reto final\n",
    "\n",
    "1. Diseña un flujo completo que:\n",
    "\n",
    "   - Tome un tema histórico o científico\n",
    "\n",
    "   - Genere un resumen creativo\n",
    "\n",
    "   - Transforme ese resumen en poema, diálogo o cuento\n",
    "\n",
    "   - Traduza a otro idioma\n",
    "\n",
    "   - Evalúe cuál cadena produce el resultado más coherente y creativo\n",
    "\n",
    "2. Documenta tus decisiones de diseño de prompts, indicando:\n",
    "\n",
    "   - Qué instrucciones del sistema usaste\n",
    "\n",
    "   - Qué variables incluiste en las plantillas\n",
    "\n",
    "    - Cómo encadenaste prompts y por qué"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
