{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60bd537",
   "metadata": {},
   "source": [
    "# 4. LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc3dd1",
   "metadata": {},
   "source": [
    "Los modelos de lenguaje actuales permiten no solo generar texto coherente, sino también obtener representaciones vectoriales (embeddings) de frases o documentos, que capturan su significado semántico.\n",
    "En este ejercicio utilizaremos:\n",
    "\n",
    "Modelos abiertos de Hugging Face (GPT-2 o similares) para generación de texto.\n",
    "\n",
    "Embeddings para representar reseñas de productos y poder compararlas entre sí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05290c",
   "metadata": {},
   "source": [
    "## Parte 1: Generación de texto con modelos abiertos\n",
    "\n",
    "- Autentícate en Hugging Face Hub usando tu token.\n",
    "\n",
    "- Carga un modelo de generación de texto abierto (por ejemplo, \"gpt2\", \"tiiuae/falcon-7b-instruct\" o cualquier otro modelo ligero disponible).\n",
    "\n",
    "- Genera secuencias de texto a partir de distintos prompts:\n",
    "\n",
    "   \"La inteligencia artificial en educación \"\n",
    "\n",
    "    \"El futuro de la música es \"\n",
    "\n",
    "    \"Un consejo para programadores principiantes es \"\n",
    "\n",
    "- Varía el parámetro max_new_tokens y observa cómo cambia la coherencia de los textos generados.\n",
    "\n",
    "¿Qué ocurre cuando el número de tokens es muy bajo? ¿Y cuando es muy alto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd66e6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32164053",
   "metadata": {},
   "source": [
    "## Parte 2: Representación semántica con embeddings\n",
    "\n",
    "- Descarga el dataset de reseñas de instrumentos musicales desde:\n",
    "https://raw.githubusercontent.com/keitazoumana/Experimentation-Data/main/Musical_instruments_reviews.csv\n",
    "\n",
    "- Conserva únicamente la columna \"reviewText\".\n",
    "\n",
    "- Implementa una función get_embedding(text) que convierta un texto en un vector numérico usando un modelo de embeddings (puedes usar OpenAI embeddings o un modelo de embeddings abierto como \"sentence-transformers/all-MiniLM-L6-v2\" desde Hugging Face).\n",
    "\n",
    "- Genera embeddings para un subconjunto de 100 reseñas y guárdalos en un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bf73a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5f515a",
   "metadata": {},
   "source": [
    "## Parte 3: Exploración del espacio vectorial\n",
    "\n",
    "- Elige dos reseñas del dataset y calcula la similitud coseno entre sus embeddings.\n",
    "\n",
    "   ¿Qué significa que el valor sea cercano a 1?\n",
    "\n",
    "   ¿Y si es cercano a 0?\n",
    "\n",
    "- Elige una reseña cualquiera y encuentra las 5 reseñas más similares en el conjunto.\n",
    "\n",
    "- Representa los embeddings en 2D usando PCA o t-SNE y colorea los puntos según la longitud del texto (reseñas cortas vs largas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423de0d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae7003e",
   "metadata": {},
   "source": [
    "## Parte 4: Aplicación práctica\n",
    "\n",
    "- Implementa una función de búsqueda semántica:\n",
    "\n",
    "  El usuario introduce una consulta en lenguaje natural (ejemplo: “buen sonido de guitarra”).\n",
    "\n",
    "  Se calcula su embedding.\n",
    "\n",
    "  Se devuelven las reseñas más cercanas en el espacio vectorial.\n",
    "\n",
    "- Prueba la función con al menos 3 consultas distintas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fb9ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7805c3bc",
   "metadata": {},
   "source": [
    "## Parte 5 (Avanzado - Opcional)\n",
    "\n",
    "- Usa el modelo de generación de texto para resumir las reseñas más relevantes encontradas en la búsqueda semántica.\n",
    "\n",
    "- Compara la coherencia de los resúmenes generados por un modelo abierto (GPT-2, Falcon) frente a un modelo más potente (ej. OpenAI GPT-4 si está disponible).\n",
    "\n",
    "- Reflexiona:\n",
    "\n",
    "¿Qué limitaciones tienen los modelos abiertos en comparación con los cerrados?\n",
    "\n",
    "¿Cuándo sería suficiente usar un modelo abierto y cuándo sería preferible uno cerrado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64249177",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
