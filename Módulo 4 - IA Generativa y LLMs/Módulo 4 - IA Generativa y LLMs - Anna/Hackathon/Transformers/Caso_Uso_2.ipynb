{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db6b4e1",
   "metadata": {},
   "source": [
    "# Caso Práctico: Extracción Automática de Entidades en Tickets de Soporte para \"TechSupportPro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8e6fc",
   "metadata": {},
   "source": [
    "**Empresa Ficticia**: TechSupportPro Contexto: \"TechSupportPro\" ofrece software y hardware a miles de empresas. Su departamento de soporte técnico recibe cientos de tickets (correos electrónicos y formularios web) cada hora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4392172",
   "metadata": {},
   "source": [
    "Actualmente, un equipo de \"triaje\" lee cada ticket manualmente para identificar la información clave y rellenar los campos en su sistema interno (como Zendesk o Jira). Este proceso es lento y propenso a errores. La información que necesitan extraer es:\n",
    "\n",
    "- PRODUCTO: El nombre del software o hardware que falla (p.ej., \"Firewall Serie XG\", \"App Agente v3.1\").\n",
    "\n",
    "- ERROR_CODE: Códigos de error específicos (p.ej., \"0x00A45F\", \"E_CONN_REFUSED\").\n",
    "\n",
    "- OS: El sistema operativo del cliente (p.ej., \"Windows Server 2022\", \"Ubuntu 22.04\").\n",
    "\n",
    "**El Desafío**: La empresa quiere construir un modelo de IA que lea el texto no estructurado de un ticket y etiquete automáticamente cada palabra (o \"token\") que corresponda a una de estas entidades. Esto se conoce como un problema de Reconocimiento de Entidades Nombradas (NER) o Clasificación de Tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d73cc",
   "metadata": {},
   "source": [
    "Por ejemplo:\n",
    "\n",
    "Ticket: \"Mi Firewall Serie XG [PRODUCTO] da el error 0x00A45F [ERROR_CODE] en Windows Server 2022 [OS].\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e7b9f",
   "metadata": {},
   "source": [
    "## Enunciado del Problema y Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c23c7",
   "metadata": {},
   "source": [
    "Tu objetivo es entrenar un modelo Transformer (como BERT-base-cased, DistilBert o cualquier otro que hayas utilizado en clase) para que funcione como un extractor de entidades (NER). El modelo debe tomar una frase y devolver una etiqueta para cada token de esa frase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0c324",
   "metadata": {},
   "source": [
    "**Conjunto de Datos:** Se te proporciona (o generarás) un archivo tech_support_tickets_ner.csv. Este formato es diferente al problema anterior. En lugar de una etiqueta por reseña, tienes una etiqueta por palabra.\n",
    "\n",
    "El CSV tiene 3 columnas:\n",
    "\n",
    "- ticket_id: Identificador de la frase (un mismo ticket puede tener varias frases).\n",
    "\n",
    "- tokens: Una lista de palabras (ya tokenizadas por espacio) que forman la frase.\n",
    "\n",
    "- ner_tags: Una lista de etiquetas (en formato IOB2) que se corresponde exactamente con la lista de tokens.\n",
    "\n",
    "**Esquema de Etiquetado (IOB2):**\n",
    "\n",
    "- O: (Outside) La palabra no es ninguna entidad de interés.\n",
    "\n",
    "- B-PROD: (Beginning) La palabra es el comienzo de una entidad de tipo Producto.\n",
    "\n",
    "- I-PROD: (Inside) La palabra es la continuación de una entidad de tipo Producto.\n",
    "\n",
    "- B-ERR: (Beginning) Comienzo de un Error Code.\n",
    "\n",
    "- I-ERR: (Inside) Continuación de un Error Code.\n",
    "\n",
    "- B-OS: (Beginning) Comienzo de un Sistema Operativo.\n",
    "\n",
    "- I-OS: (Inside) Continuación de un Sistema Operativo.\n",
    "\n",
    "Ejemplo de una fila del CSV: | ticket_id | tokens | ner_tags | | :--- | :--- | :--- | | tkt_001 | ['El', 'Firewall', 'Serie', 'XG', 'falla', 'con', 'E_CONN_REFUSED'] | ['O', 'B-PROD', 'I-PROD', 'I-PROD', 'O', 'O', 'B-ERR'] |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3fc60",
   "metadata": {},
   "source": [
    "## Requisitos del Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c7797",
   "metadata": {},
   "source": [
    "1. Carga y Preparación de Datos:\n",
    "\n",
    "- Cargar el .csv tech_support_tickets_ner.csv. Las columnas tokens y ner_tags se cargarán como strings. Deberás convertirlas de nuevo a listas.\n",
    "\n",
    "- Crear los mapeos (diccionarios) entre las etiquetas (ej. 'B-PROD') y sus IDs numéricos (ej. 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b2c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f687b1c7",
   "metadata": {},
   "source": [
    "2. Tokenización y Alineación (El Reto de NER):\n",
    "\n",
    "- Elegir un tokenizador pre-entrenado (ej. BertTokenizerFast).\n",
    "\n",
    "- Reto Clave: El tokenizador (WordPiece/BPE) dividirá palabras que en tus datos originales eran un solo token. Por ejemplo, \"Firewall\" puede seguir siendo \"Firewall\", pero \"E_CONN_REFUSED\" podría dividirse en ['E', '_', 'CONN', '_', 'REFUSED'].\n",
    "\n",
    "- Debes implementar la lógica para alinear tus ner_tags con los nuevos sub-tokens generados por el tokenizador. La regla estándar es:\n",
    "\n",
    " La etiqueta B- solo se aplica al primer sub-token.\n",
    "\n",
    " Las etiquetas I- se aplican a los sub-tokens siguientes de la misma palabra.\n",
    "\n",
    " Los tokens especiales (como [CLS], [SEP]) deben recibir una etiqueta especial (p.ej., -100) para que sean ignorados por la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37fb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce529473",
   "metadata": {},
   "source": [
    "3. Configuración del Modelo:\n",
    "\n",
    "- Cargar un modelo Transformer pre-entrenado para Clasificación de Tokens (ej. BertForTokenClassification, AutoModelForTokenClassification o cualquier otro que hayas utilizado en clase).\n",
    "\n",
    "- Asegúrate de configurarlo con el número correcto de etiquetas (IDs) que has definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e26de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd3cf6a",
   "metadata": {},
   "source": [
    "4. Entrenamiento (Fine-Tuning):\n",
    "\n",
    "- Configurar TrainingArguments y el Trainer.\n",
    "\n",
    "- Entrenar el modelo (fine-tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee893a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d6a979f",
   "metadata": {},
   "source": [
    "5. Evaluación:\n",
    "\n",
    "- Utilizar el conjunto de prueba para evaluar el rendimiento.\n",
    "\n",
    "- Importante: La métrica de \"accuracy\" simple no es útil aquí. Debes usar una biblioteca como seqeval (el estándar de oro para NER) para calcular la Precisión, Recall y F1-Score a nivel de entidad (no de token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbfc42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5100466c",
   "metadata": {},
   "source": [
    "6. Función de Inferencia:\n",
    "\n",
    "- Crear una función final extraer_entidades(texto) que reciba un string de texto crudo, lo procese (tokenice, prediga, y agrupe los sub-tokens) y devuelva una lista de las entidades encontradas.\n",
    "\n",
    "Ejemplo de salida: [{'entidad': 'Firewall Serie XG', 'tipo': 'PRODUCTO'}, {'entidad': 'E_CONN_REFUSED', 'tipo': 'ERROR_CODE'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5b667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
