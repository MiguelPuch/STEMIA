{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ec1ea2",
   "metadata": {},
   "source": [
    "# Caso Práctico: Sistema Inteligente de Clasificación de Reseñas para \"GastroReseñas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397d75b",
   "metadata": {},
   "source": [
    "**Empresa  GastroReseñas Contexto**: \"GastroReseñas\" es una plataforma web líder en la recopilación de opiniones sobre restaurantes. Diariamente, miles de usuarios publican reseñas sobre sus experiencias gastronómicas. Actualmente, la plataforma solo muestra una calificación de 1 a 5 estrellas.\n",
    "\n",
    "La empresa quiere lanzar una nueva funcionalidad: un \"resumen de opinión\" que etiquete automáticamente cada reseña con aspectos clave mencionados por el usuario. Esto permitiría a los nuevos clientes filtrar, por ejemplo, por reseñas que hablen positivamente del \"Servicio\" o negativamente del \"Precio\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b6ac3",
   "metadata": {},
   "source": [
    "**El Desafío**: El volumen de reseñas es demasiado grande para ser etiquetado manualmente. El equipo de \"GastroReseñas\" ha recopilado un conjunto de datos (un archivo .csv) donde han etiquetado manualmente 10,000 reseñas de ejemplo. El problema es que una misma reseña puede referirse a múltiples aspectos. Por ejemplo:\n",
    "\n",
    "- Reseña: \"La comida estaba deliciosa, pero el camarero fue muy lento.\"\n",
    "\n",
    "- Etiquetas deseadas: [Comida_Positivo], [Servicio_Negativo]\n",
    "\n",
    "Esto se conoce como un problema de clasificación de texto multietiqueta (multi-label classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1634f33c",
   "metadata": {},
   "source": [
    "## Enunciado del Problema y Tarea "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1ec0f",
   "metadata": {},
   "source": [
    "Tu objetivo es desarrollar un sistema basado en un modelo Transformer (como BERT, DistilBERT o alguno similar que hayamos dado en clase) capaz de leer el texto de una nueva reseña de restaurante y asignar todas las etiquetas que correspondan de una lista predefinida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afb3e0",
   "metadata": {},
   "source": [
    "\n",
    "Conjunto de Datos: Se te proporciona un archivo gastro_reseñas_etiquetadas.csv. Las columnas relevantes son:\n",
    "\n",
    "- id_reseña: Identificador único.\n",
    "\n",
    "- texto_reseña: El texto completo de la opinión del usuario.\n",
    "\n",
    "- etiqueta_comida_pos: (1 o 0)\n",
    "\n",
    "- etiqueta_comida_neg: (1 o 0)\n",
    "\n",
    "- etiqueta_servicio_pos: (1 o 0)\n",
    "\n",
    "- etiqueta_servicio_neg: (1 o 0)\n",
    "\n",
    "- etiqueta_ambiente_pos: (1 o 0)\n",
    "\n",
    "- etiqueta_ambiente_neg: (1 o 0)\n",
    "\n",
    "- etiqueta_precio_pos: (1 o 0)\n",
    "\n",
    "- etiqueta_precio_neg: (1 o 0)\n",
    "\n",
    "(Nota: Un 1 indica que la etiqueta aplica, un 0 que no aplica. Una misma fila puede tener múltiples 1s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f003b",
   "metadata": {},
   "source": [
    "## Requisitos del Proyecto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1a79a",
   "metadata": {},
   "source": [
    "\n",
    "Debes configurar un script o notebook de Python que implemente la solución completa utilizando la biblioteca transformers (de Hugging Face) y un framework como PyTorch o TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ede594",
   "metadata": {},
   "source": [
    "## Pasos Obligatorios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acaaf2",
   "metadata": {},
   "source": [
    "1. Carga y Preparación de Datos:\n",
    "\n",
    "- Cargar el archivo gastro_reseñas_etiquetadas.csv (usando pandas).\n",
    "\n",
    "- Preparar los datos para el modelo. Dado que es un problema multietiqueta, debes consolidar las columnas de etiquetas en un único formato que el modelo pueda entender (p.ej., un array de 8 dimensiones por cada reseña, como [1, 0, 0, 1, 0, 0, 0, 0]).\n",
    "\n",
    "- Dividir los datos en conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7084eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_reseña                                       texto_reseña  \\\n",
      "0  gr_00001  El local estaba sucio y descuidado. En resumen...   \n",
      "1  gr_00002  La comida estaba deliciosa. El local tiene una...   \n",
      "2  gr_00003  Fue carísimo, un auténtico robo. El pollo esta...   \n",
      "3  gr_00004  Era nuestra primera vez en este sitio.. Fuimos...   \n",
      "4  gr_00005  Tengo sentimientos encontrados sobre este luga...   \n",
      "\n",
      "   etiqueta_comida_pos  etiqueta_servicio_pos  etiqueta_ambiente_pos  \\\n",
      "0                    0                      0                      0   \n",
      "1                    1                      1                      1   \n",
      "2                    0                      0                      0   \n",
      "3                    0                      0                      0   \n",
      "4                    0                      0                      1   \n",
      "\n",
      "   etiqueta_precio_pos  etiqueta_comida_neg  etiqueta_servicio_neg  \\\n",
      "0                    0                    0                      0   \n",
      "1                    0                    0                      0   \n",
      "2                    0                    1                      1   \n",
      "3                    0                    0                      0   \n",
      "4                    0                    0                      0   \n",
      "\n",
      "   etiqueta_ambiente_neg  etiqueta_precio_neg  \n",
      "0                      1                    0  \n",
      "1                      0                    0  \n",
      "2                      0                    1  \n",
      "3                      0                    0  \n",
      "4                      0                    0  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo gastro_reseñas_etiquetadas.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Data/gastro_reseñas_etiquetadas.csv')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ace6748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_reseña           etiquetas_array\n",
      "0  gr_00001  [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "1  gr_00002  [1, 1, 1, 0, 0, 0, 0, 0]\n",
      "2  gr_00003  [0, 0, 0, 0, 1, 1, 0, 1]\n",
      "3  gr_00004  [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4  gr_00005  [0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos: unificar columnas de etiqueta en un array de 8 dimensiones\n",
    "import numpy as np\n",
    "etiquetas = df[['etiqueta_comida_pos', 'etiqueta_servicio_pos', 'etiqueta_ambiente_pos', 'etiqueta_precio_pos', 'etiqueta_comida_neg', 'etiqueta_servicio_neg', 'etiqueta_ambiente_neg', 'etiqueta_precio_neg']].values\n",
    "df['etiquetas_array'] = [list(map(int, etiqueta)) for etiqueta in etiquetas]\n",
    "# Mostrar las primeras filas del DataFrame con la nueva columna\n",
    "print(df[['id_reseña', 'etiquetas_array']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5804bf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 8000\n",
      "Tamaño del conjunto de prueba: 2000\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f'Tamaño del conjunto de entrenamiento: {len(train_df)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4dbfa",
   "metadata": {},
   "source": [
    "2. Tokenización:\n",
    "\n",
    "- Elegir e instanciar un tokenizador pre-entrenado (ej. DistilBertTokenizerFast o cualquier otro que hayais utilizado en clase).\n",
    "\n",
    "- Tokenizar los texto_reseña para que el modelo Transformer pueda procesarlos (generando input_ids y attention_mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdc5063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_reseña', 'texto_reseña', 'etiqueta_comida_pos', 'etiqueta_servicio_pos', 'etiqueta_ambiente_pos', 'etiqueta_precio_pos', 'etiqueta_comida_neg', 'etiqueta_servicio_neg', 'etiqueta_ambiente_neg', 'etiqueta_precio_neg', 'etiquetas_array']\n"
     ]
    }
   ],
   "source": [
    "# Verificar nombres de columnas\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c8e7fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 8840, 28667, 8462, 8943, 4360, 1010, 2566, 2080, 9530, 24501, 2121, 12044, 1012, 27490, 2891, 14163, 2100, 4180, 2891, 9530, 2474, 16091, 12380, 1012, 3449, 2334, 5495, 2638, 14477, 25545, 21736, 3653, 9793, 3736, 1012, 3449, 2033, 5558, 2099, 18858, 10861, 2002, 4013, 9024, 2080, 4372, 2172, 2080, 5495, 8737, 2080, 1012, 16839, 8823, 16089, 26534, 14163, 2100, 5915, 2080, 1012, 11865, 2063, 14477, 2310, 27266, 2050, 29542, 20782, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Elegir e instanciar un tokenizador pre-entrenado (DistilBertTokenizerFast)\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenizar las reseñas generando input_ids y attention_masks\n",
    "train_encodings = tokenizer(train_df['texto_reseña'].tolist(), padding='max_length', truncation=True, max_length=128)\n",
    "test_encodings = tokenizer(test_df['texto_reseña'].tolist(), padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Mostrar un ejemplo de tokenización\n",
    "print(train_encodings['input_ids'][0])\n",
    "print(train_encodings['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e310a",
   "metadata": {},
   "source": [
    "3. Configuración del Modelo:\n",
    "\n",
    "- Cargar un modelo Transformer pre-entrenado (ej. DistilBertForSequenceClassification o cualquier otro que hayais utilizado en clase) desde la biblioteca transformers.\n",
    "\n",
    "- Importante: Al cargar el modelo, deberás configurarlo específicamente para un problema de clasificación multietiqueta (multi-label), asegurándote de que la capa de salida tenga 8 neuronas (una por cada etiqueta posible) y utilice una función de activación y pérdida adecuadas (p.ej., Sigmoide en la salida y BCEWithLogitsLoss como función de pérdida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616640e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo de Transormer pre-entrenado: DistilBertForSequenceClassification\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=8, problem_type=\"multi_label_classification\")\n",
    "\n",
    "# Comprobar la arquitectura del modelo\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684076a",
   "metadata": {},
   "source": [
    "4. Entrenamiento (Fine-Tuning):\n",
    "\n",
    "- Configurar los TrainingArguments (o un bucle de entrenamiento manual).\n",
    "\n",
    "- Implementar el \"fine-tuning\" del modelo sobre el conjunto de datos de entrenamiento, monitorizando la pérdida en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57ed65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 22:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.250254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./modelo_gastro_final\\\\tokenizer_config.json',\n",
       " './modelo_gastro_final\\\\special_tokens_map.json',\n",
       " './modelo_gastro_final\\\\vocab.txt',\n",
       " './modelo_gastro_final\\\\added_tokens.json',\n",
       " './modelo_gastro_final\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento (Fine-Tuning)\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Preparar las etiquetas como arrays numpy para asegurar el formato correcto\n",
    "train_labels = [[float(x) for x in label] for label in train_df['etiquetas_array'].tolist()]\n",
    "test_labels = [[float(x) for x in label] for label in test_df['etiquetas_array'].tolist()]\n",
    "\n",
    "# Convertir encodings y etiquetas a Dataset de Hugging Face\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': test_labels\n",
    "})\n",
    "\n",
    "# Configurar el formato del dataset\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Configurar los TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',             # directorio para guardar los resultados\n",
    "    num_train_epochs=1,                 # número de épocas (subir si no mejora y bajar si hay overfitting)\n",
    "    per_device_train_batch_size=64,     # tamaño del batch para entrenamiento\n",
    "    per_device_eval_batch_size=64,      # tamaño del batch para evaluación\n",
    "    learning_rate=3e-5,                 # tasa de aprendizaje (más bajo si no converge y más alto si entrena lento)\n",
    "    warmup_steps=50,                   # pasos de calentamiento\n",
    "    weight_decay=0.01,                  # decaimiento del peso (aumentar si hay overfitting y disminuir si no hay overfitting)\n",
    "    logging_dir='./logs',               # directorio para los logs\n",
    "    logging_steps=20,                  # pasos entre logs\n",
    "    eval_strategy=\"epoch\",              # estrategia de evaluación\n",
    "    save_strategy=\"epoch\",              # estrategia de guardado\n",
    "    load_best_model_at_end=True,        # cargar el mejor modelo al final\n",
    ")\n",
    "\n",
    "# Crear el Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save_pretrained('./modelo_gastro_final')\n",
    "tokenizer.save_pretrained('./modelo_gastro_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ba096",
   "metadata": {},
   "source": [
    "5. Evaluación:\n",
    "\n",
    "- Una vez entrenado el modelo, usar el conjunto de prueba (datos que el modelo nunca ha visto) para evaluar su rendimiento.\n",
    "\n",
    "- Calcular métricas apropiadas para clasificación multietiqueta, como el F1-Score (micro y macro), Precisión (micro) y Recall (micro).\n",
    "\n",
    "Nota: No se puede usar 'accuracy' simple, ya que una predicción puede ser parcialmente correcta (acertar 3 de 8 etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a2c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ST09\\Documents\\GitHub\\STEMIA\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8123396212209676\n",
      "Precision: 0.8512518968371363\n",
      "Recall: 0.7819742706792416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       595\n",
      "           1       0.95      0.97      0.96       623\n",
      "           2       0.97      0.99      0.98       627\n",
      "           3       0.99      0.99      0.99       637\n",
      "           4       0.66      0.52      0.58       405\n",
      "           5       0.67      0.55      0.61       381\n",
      "           6       0.74      0.57      0.64       415\n",
      "           7       0.83      0.66      0.74       432\n",
      "\n",
      "   micro avg       0.89      0.83      0.86      4115\n",
      "   macro avg       0.85      0.78      0.81      4115\n",
      "weighted avg       0.88      0.83      0.85      4115\n",
      " samples avg       0.76      0.75      0.74      4115\n",
      "\n",
      "Micro F1 Score: 0.8573232323232324\n",
      "Micro Precision: 0.8922470433639947\n",
      "Micro Recall: 0.8250303766707169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ST09\\Documents\\GitHub\\STEMIA\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ST09\\Documents\\GitHub\\STEMIA\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ST09\\Documents\\GitHub\\STEMIA\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "import torch\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "logits = predictions.predictions\n",
    "\n",
    "predicted_labels = (torch.sigmoid(torch.tensor(logits)) >= 0.5).int().numpy() # Umbral de 0.5 para clasificación multilabel\n",
    "\n",
    "# Calcular métricas\n",
    "f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
    "precision = precision_score(test_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(classification_report(test_labels, predicted_labels))\n",
    "\n",
    "# Calcular micro F1, precision y recall\n",
    "f1_micro = f1_score(test_labels, predicted_labels, average='micro')\n",
    "precision_micro = precision_score(test_labels, predicted_labels, average='micro')\n",
    "recall_micro = recall_score(test_labels, predicted_labels, average='micro')\n",
    "\n",
    "print(f\"Micro F1 Score: {f1_micro}\")\n",
    "print(f\"Micro Precision: {precision_micro}\")\n",
    "print(f\"Micro Recall: {recall_micro}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316b002",
   "metadata": {},
   "source": [
    "6. Función de Inferencia:\n",
    "\n",
    "- Crear una función final llamada clasificar_reseña(texto) que reciba un string con una nueva reseña y devuelva una lista con los nombres de las etiquetas predichas (ej. ['Comida_Positivo', 'Servicio_Negativo'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155b825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas predichas: [0 0 0 0 0 0 0 0]\n",
      "Probabilidades: [0.12766056 0.12475957 0.49528953 0.15224287 0.10678678 0.1413088\n",
      " 0.13246131 0.11023088]\n"
     ]
    }
   ],
   "source": [
    "# Función de inferencia\n",
    "def inferir_reseña(texto_reseña):\n",
    "    # Cargar el modelo y el tokenizador guardados\n",
    "    from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "    import torch\n",
    "\n",
    "    modelo_cargado = DistilBertForSequenceClassification.from_pretrained('./modelo_gastro_final')\n",
    "    tokenizador_cargado = DistilBertTokenizerFast.from_pretrained('./modelo_gastro_final')\n",
    "\n",
    "    # Tokenizar la reseña\n",
    "    encoding = tokenizador_cargado(texto_reseña, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "    # Realizar la predicción\n",
    "    with torch.no_grad():\n",
    "        outputs = modelo_cargado(**encoding)\n",
    "        logits = outputs.logits\n",
    "        probabilidades = torch.sigmoid(logits).squeeze().numpy()\n",
    "\n",
    "    # Aplicar umbral para obtener etiquetas binarias\n",
    "    etiquetas_predichas = (probabilidades >= 0.5).astype(int)\n",
    "\n",
    "    return etiquetas_predichas, probabilidades\n",
    "\n",
    "# Ejemplo de uso de la función de inferencia\n",
    "resania_ejemplo = \"El ambiente del restaurante era acogedor, pero el servicio fue lento y la comida no estaba a la altura de mis expectativas.\"\n",
    "etiquetas_predichas, probabilidades = inferir_reseña(resania_ejemplo)\n",
    "print(f\"Etiquetas predichas: {etiquetas_predichas}\")\n",
    "print(f\"Probabilidades: {probabilidades}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
