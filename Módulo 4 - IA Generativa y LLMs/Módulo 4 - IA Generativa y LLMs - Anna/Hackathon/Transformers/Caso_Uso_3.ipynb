{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacc7e7c",
   "metadata": {},
   "source": [
    "# Caso Práctico: Rescate del Chatbot de Clasificación de \"MediQuery\" (Diagnóstico de Overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc194140",
   "metadata": {},
   "source": [
    "**Empresa MediQuery Contexto**: \"MediQuery\" es una startup de telemedicina. Han lanzado un chatbot para clasificar las consultas entrantes de los pacientes y dirigirlas al departamento correcto. Las categorías son: [Cita_Medica], [Facturacion], [Consulta_Resultados] y [Urgencia_Medica]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a94f9",
   "metadata": {},
   "source": [
    "El Problema (¡Crisis Real!): El equipo junior entrenó un modelo bert-base-uncased usando un dataset pequeño de 1,000 ejemplos etiquetados a mano. En sus notebooks, el modelo alcanzó un 99.8% de accuracy en el conjunto de entrenamiento y un 98% en el de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed2031",
   "metadata": {},
   "source": [
    "Sin embargo, una semana después de lanzarlo a producción, el sistema colapsó. El modelo está clasificando consultas como \"Me duele el pecho y no puedo respirar\" en la categoría [Facturacion]. El modelo no ha generalizado; ha memorizado los 1,000 ejemplos de entrenamiento. Esto es un caso clásico de sobreajuste (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b37a8a",
   "metadata": {},
   "source": [
    "**El Desafío:** Tú eres el/la Ingeniero/a de ML que han contratado para arreglar el desastre. Tu objetivo no es (solo) entrenar un modelo, sino diagnosticar, solucionar y demostrar cómo evitar que el sobreajuste destruya la fiabilidad del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f893294",
   "metadata": {},
   "source": [
    "## Enunciado del Problema y Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0591a7",
   "metadata": {},
   "source": [
    "Tu objetivo es replicar el error del equipo junior y luego implementar dos estrategias de regularización/optimización de Transformers para rescatar el modelo y hacerlo generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad7b59",
   "metadata": {},
   "source": [
    "Conjunto de Datos: Se te proporciona un archivo mediquery_1k_samples.csv. Es un dataset intencionalmente pequeño y \"fácil\" de memorizar.\n",
    "\n",
    "- id_consulta: Identificador único.\n",
    "\n",
    "- texto_consulta: El texto del paciente.\n",
    "\n",
    "- etiqueta: (Facturacion, Cita_Medica, Consulta_Resultados, Urgencia_Medica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b864fd",
   "metadata": {},
   "source": [
    "## Pasos Obligatorios:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82aff3",
   "metadata": {},
   "source": [
    "1. Carga y Preparación de Datos:\n",
    "\n",
    "- Cargar el mediquery_1k_samples.csv.\n",
    "\n",
    "- Convertir las etiquetas de texto a IDs numéricos.\n",
    "\n",
    "- Dividir los datos (ej. 80% entrenamiento, 20% validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f43f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a59d9d",
   "metadata": {},
   "source": [
    "2. Paso 1: Replicar el Desastre (El Modelo Sobreajustado)\n",
    "\n",
    "- Cargar el tokenizador y el modelo \"grande\" (bert-base-uncased).\n",
    "\n",
    "- Configurar los TrainingArguments para forzar el sobreajuste:\n",
    "\n",
    "*  Entrenar durante un número alto de épocas (ej. num_train_epochs=50).\n",
    "\n",
    "*  Usar un learning_rate estándar (ej. 5e-5).\n",
    "\n",
    "- Entrenar el modelo.\n",
    "\n",
    "- Entregable de Diagnóstico: Generar un gráfico (usando matplotlib o similar) que muestre la training_loss vs. la validation_loss por época. Debes mostrar visualmente cómo la training_loss sigue bajando mientras la validation_loss se estanca o empieza a subir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3998bf9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a012c77",
   "metadata": {},
   "source": [
    "3. Paso 2: Rescate - Estrategia A (Regularización del Entrenamiento)\n",
    "\n",
    "- Hipótesis: El modelo es bueno, pero entrenó demasiado tiempo.\n",
    "\n",
    "- antener el modelo bert-base-uncased.\n",
    "\n",
    "- Modificar los TrainingArguments para implementar Early Stopping:\n",
    "\n",
    " * evaluation_strategy = \"epoch\"\n",
    "\n",
    " * save_strategy = \"epoch\"\n",
    "\n",
    " * load_best_model_at_end = True (Esto es crucial: el Trainer recargará las pesas del mejor epoch, no del último).\n",
    "\n",
    "- Re-entrenar el modelo. El Trainer debería detenerse automáticamente (ej. en la época 3 o 4) cuando la validation_loss deje de mejorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d6793",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb0fda5",
   "metadata": {},
   "source": [
    "4. Paso 3: Rescate - Estrategia B (Reducción de Arquitectura)\n",
    "\n",
    "- Hipótesis: El modelo (bert-base) es demasiado grande y potente para un dataset tan pequeño. Es como usar un motor de Fórmula 1 para ir a comprar el pan: memorizará el camino.\n",
    "\n",
    "- Cambiar la arquitectura del modelo. En lugar de bert-base-uncased, carga un modelo mucho más ligero, como prajjwal1/bert-tiny o google/bert_uncased_L-4_H-256_A-4 (un BERT más pequeño).\n",
    "\n",
    "- Nota: Asegúrate de usar el mismo tokenizador (bert-base-uncased) si el modelo ligero lo comparte, o carga el tokenizador específico del modelo ligero.\n",
    "\n",
    "- Entrena este modelo ligero (puedes usar el Early Stopping del Paso 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5acce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b3a2b6",
   "metadata": {},
   "source": [
    "5. Paso 4: Análisis y Conclusión:\n",
    "\n",
    "- Crear una función de inferencia clasificar_consulta(texto) que funcione con tu modelo rescatado.\n",
    "\n",
    "- Probar el modelo con frases nuevas (no vistas en el CSV) que sean ambiguas o críticas:\n",
    "\n",
    "Ej 1 (Crítico): \"Me duele el pecho y me cuesta respirar.\"\n",
    "\n",
    "Ej 2 (Facturación): \"¿Por qué el cargo de mi última visita es tan alto?\"\n",
    "\n",
    "Ej 3 (Ambiguo): \"No sé qué hacer con los resultados que me dieron.\"\n",
    "\n",
    "- Redactar/comentamos una breve conclusión (en Markdown) explicando por qué la Estrategia A o B es la mejor solución para \"MediQuery\" en términos de coste, velocidad y fiabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e92fe2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
