{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc0eb25",
   "metadata": {},
   "source": [
    "# Construcción de una Base de Datos Vectorial desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e7e5b",
   "metadata": {},
   "source": [
    "Una empresa llamada DataFind quiere crear su propia base de datos vectorial interna, sin depender de servicios externos.\n",
    "Necesitan almacenar, indexar y buscar información basada en significado, no solo por coincidencia de texto.\n",
    "\n",
    "Tu misión es simular una BDV completa capaz de:\n",
    "\n",
    "Almacenar embeddings.\n",
    "\n",
    "Buscar por similitud.\n",
    "\n",
    "Implementar filtros por metadatos.\n",
    "\n",
    "Medir la eficiencia y calidad de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8782fa9",
   "metadata": {},
   "source": [
    "## Objetivos de la práctica\n",
    "\n",
    "1. Generar embeddings simulados\n",
    "\n",
    "- Cargar csv documentos_datafind.csv.\n",
    "\n",
    "- Convertirlos en vectores de alta dimensión (usando numpy para simular embeddings).\n",
    "\n",
    "2. Implementar componentes internos de la BDV:\n",
    "\n",
    "- Storage Engine: guardar los vectores y metadatos.\n",
    "\n",
    "- Index Builder: crear índices con estrategias de agrupamiento (simular IVF, HNSW o PQ).\n",
    "\n",
    "- Query Engine: calcular similitudes (cosine y euclidean).\n",
    "\n",
    "- Metadata Store: almacenar texto original, etiquetas o categorías.\n",
    "\n",
    "3. Implementar consultas vectoriales\n",
    "\n",
    "- Permitir que el usuario escriba una consulta y el sistema devuelva los documentos más similares.\n",
    "\n",
    "- Simular embeddings de la consulta con el mismo método.\n",
    "\n",
    "4. Agregar filtrado por metadatos\n",
    "\n",
    "- Permitir buscar solo en documentos de una categoría (ej. “Tecnología”, “Salud”, “Educación”).\n",
    "\n",
    "5. Evaluar el rendimiento y calidad de la búsqueda:\n",
    "\n",
    "- Calcular tiempo de consulta.\n",
    "\n",
    "- Evaluar qué métrica (cosine o euclidean) devuelve resultados más relevantes.\n",
    "\n",
    "6. Simular optimización del índice:\n",
    "\n",
    "- Comparar tiempos de búsqueda con distintas estrategias (sin índice, con IVF, con HNSW).\n",
    "\n",
    "- Analizar cuál ofrece el mejor equilibrio entre velocidad y precisión.\n",
    "\n",
    "7. Generar un informe final automático:\n",
    "\n",
    "- Guardar resultados de las consultas, métricas y tiempos en un archivo reporte_resultados.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65117e3",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add66edf",
   "metadata": {},
   "source": [
    "Cargamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b25ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14508f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./Data/documentos_datafind.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a0cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   categoria                   titulo  \\\n",
      "0   1  Tecnología            Avances en IA   \n",
      "1   2       Salud      Nuevos tratamientos   \n",
      "2   3   Educación   Aprendizaje automático   \n",
      "3   4    Economía        Mercados globales   \n",
      "4   5     Ciencia  Descubrimiento espacial   \n",
      "\n",
      "                                           contenido  \n",
      "0  La inteligencia artificial está transformando ...  \n",
      "1  Se desarrollan terapias genéticas para enferme...  \n",
      "2  El machine learning se utiliza en plataformas ...  \n",
      "3  Los mercados bursátiles muestran volatilidad a...  \n",
      "4  Un nuevo telescopio detecta exoplanetas simila...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1203372",
   "metadata": {},
   "source": [
    "Convertir en vectores de alta dimensión == crear embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d238d",
   "metadata": {},
   "source": [
    "Rápido sin dependencias pero no tiene significado semántico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24854f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512  # por ejemplo, 512 dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1784a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un embedding aleatorio para cada documento\n",
    "# np.random.rand genera valores entre 0 y 1\n",
    "embeddings = np.random.rand(len(df), embedding_dim)\n",
    "\n",
    "# Añadimos los embeddings al DataFrame si quieres guardarlos\n",
    "df['embedding'] = embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771ee1d",
   "metadata": {},
   "source": [
    "TF-IDF: es una métrica para medir la importancia de una palabra en un documento dentro de una colección de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e35418",
   "metadata": {},
   "source": [
    "Se calcula multiplicando dos factores: la frecuencia con la que aparece una palabra en un documento (TF) y la rareza de esa palabra en todos los documentos del corpus (IDF). Un valor alto de TF-IDF indica que la palabra es relevante para ese documento específico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./Data/documentos_datafind.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3296c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be91ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_es = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f25733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"texto_completo\"] = df[\"titulo\"].astype(str) + \". \" + df[\"contenido\"].astype(str)\n",
    "\n",
    "# Creamos vectorizador TF-IDF con stopwords en español\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=512,\n",
    "    stop_words=stop_words_es\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = vectorizer.fit_transform(df[\"texto_completo\"])\n",
    "df[\"embedding\"] = embeddings.toarray().tolist()\n",
    "\n",
    "print(df[[\"id\", \"categoria\", \"titulo\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef0987",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d901a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StorageEngine:\n",
    "    def __init__(self):\n",
    "        self.vectors = None\n",
    "        self.metadata = None\n",
    "\n",
    "    def store(self, vectors, metadata):\n",
    "        self.vectors = vectors\n",
    "        self.metadata = metadata\n",
    "        print(\"Vectores y metadatos guardados en StorageEngine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f65a7",
   "metadata": {},
   "source": [
    "## 1. IVF (Inverted File)\n",
    "\n",
    "La idea de IVF es **agrupar vectores en clusters** y buscar solo dentro del cluster más cercano:\n",
    "\n",
    "**Fórmula del cluster más cercano:**\n",
    "\n",
    "$$\n",
    "cluster\\_id = argmin_{c \\in C} || v - \\mu_c ||\n",
    "$$\n",
    "\n",
    "Donde:  \n",
    "- v = vector de embedding del documento  \n",
    "- μ_c = centroide del cluster c  \n",
    "- C = conjunto de todos los clusters  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af063bc1",
   "metadata": {},
   "source": [
    "## 2. HNSW (Hierarchical Navigable Small World)\n",
    "\n",
    "HNSW construye un **grafo de vectores** donde cada nodo apunta a sus vecinos más cercanos:\n",
    "\n",
    "**Vecinos más cercanos:**\n",
    "\n",
    "$$\n",
    "neighbors(v) = { u in V : || v - u || mínimo }\n",
    "$$\n",
    "\n",
    "Búsqueda rápida usando niveles jerárquicos:\n",
    "\n",
    "$$\n",
    "search(q) ≈ argmin_{v in G} || q - v ||\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f90722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7af92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexBuilder:\n",
    "    def __init__(self, vectors):\n",
    "        self.vectors = vectors\n",
    "        self.index = None\n",
    "\n",
    "    def build_ivf_index(self, n_clusters=10):\n",
    "        \"\"\"\n",
    "        Construye un índice IVF simulado agrupando vectores en clusters.\n",
    "        En la simulación usamos:\n",
    "\n",
    "        cluster_id = i % n_clusters  ----> para asignar un vector a algún cluster de forma rápida. Sino utilizar otro algoritmo como K-means\n",
    "        \"\"\"\n",
    "        clusters = {i: [] for i in range(n_clusters)}\n",
    "        for i, vec in enumerate(self.vectors):\n",
    "            cluster_id = i % n_clusters\n",
    "            clusters[cluster_id].append(i)\n",
    "        self.index = clusters\n",
    "        print(f\" Índice IVF simulado con {n_clusters} clusters creado.\")\n",
    "\n",
    "\n",
    "    def build_hnsw_index(self, ef_construction=200, M=16):\n",
    "        \"\"\"\n",
    "        Construye un índice HNSW real utilizando la biblioteca hnswlib.\n",
    "        \n",
    "        Parámetros:\n",
    "        - ef_construction: factor de exploración durante la construcción del índice.\n",
    "        - M: número máximo de conexiones por nodo.\n",
    "        \"\"\"\n",
    "        dim = self.vectors.shape[1]  # Dimensionalidad de los vectores\n",
    "        self.index = hnswlib.Index(space='l2', dim=dim)  # librería para construir el grafo \n",
    "        self.index.init_index(max_elements=self.vectors.shape[0], ef_construction=ef_construction, M=M)\n",
    "        self.index.add_items(self.vectors)\n",
    "\n",
    "        print(f\"✅ Índice HNSW real creado con {self.vectors.shape[0]} vectores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ac3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef05806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_engine(vectors, query_vector, top_k=5, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Función para calcular similitudes entre un vector de consulta y un conjunto de vectores.\n",
    "    \n",
    "    Parámetros:\n",
    "    - vectors: np.ndarray, matriz de vectores (n_docs x dim)\n",
    "    - query_vector: np.ndarray, vector de consulta (dim,)\n",
    "    - top_k: int, número de vecinos más cercanos a devolver\n",
    "    - metric: str, 'cosine' o 'euclidean'\n",
    "    \n",
    "    Retorna:\n",
    "    - top_indices: índices de los top_k vectores más similares\n",
    "    - top_scores: similitudes (coseno) o distancias (euclidiana) correspondientes\n",
    "    \"\"\"\n",
    "    query_vector = np.array(query_vector)\n",
    "    \n",
    "    if metric == 'cosine':\n",
    "        # Normalizamos vectores para similitud coseno\n",
    "        vectors_norm = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "        query_norm = query_vector / np.linalg.norm(query_vector)\n",
    "        # Similitud coseno = producto punto de vectores normalizados\n",
    "        sims = vectors_norm @ query_norm\n",
    "        # Obtenemos top_k índices\n",
    "        top_indices = np.argsort(sims)[::-1][:top_k]\n",
    "        top_scores = sims[top_indices]\n",
    "        \n",
    "    elif metric == 'euclidean':\n",
    "        # Distancia euclidiana\n",
    "        dists = np.linalg.norm(vectors - query_vector, axis=1)\n",
    "        top_indices = np.argsort(dists)[:top_k]\n",
    "        top_scores = dists[top_indices]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Métrica no soportada. Use 'cosine' o 'euclidean'.\")\n",
    "    \n",
    "    return top_indices, top_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16f0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_store(csv_path):\n",
    "    \"\"\"\n",
    "    Crea un MetadataStore a partir de un archivo CSV con columnas:\n",
    "    id, categoria, titulo, contenido\n",
    "\n",
    "    Devuelve un objeto MetadataStore listo para usar.\n",
    "    \"\"\"\n",
    "    class MetadataStore:\n",
    "        \"\"\"\n",
    "        Almacena los metadatos de los documentos:\n",
    "        - Texto original\n",
    "        - Etiquetas o categorías\n",
    "        \"\"\"\n",
    "        def __init__(self, df, text_column='contenido', label_column='categoria'):\n",
    "            self.ids = df['id'].tolist()\n",
    "            self.titles = df['titulo'].tolist()\n",
    "            self.texts = df[text_column].tolist()\n",
    "            self.labels = df[label_column].tolist()\n",
    "            self.df = df\n",
    "\n",
    "        def get_text(self, idx):\n",
    "            return self.texts[idx]\n",
    "\n",
    "        def get_label(self, idx):\n",
    "            return self.labels[idx]\n",
    "\n",
    "        def get_title(self, idx):\n",
    "            return self.titles[idx]\n",
    "\n",
    "        def get_metadata(self, idx):\n",
    "            return {\n",
    "                'id': self.ids[idx],\n",
    "                'title': self.titles[idx],\n",
    "                'text': self.texts[idx],\n",
    "                'label': self.labels[idx]\n",
    "            }\n",
    "\n",
    "    return MetadataStore(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39859e7e",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b10ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documentos más similares:\n",
      "\n",
      "ID: 1 | Título: Avances en IA | Categoría: Tecnología | Score: 0.7541\n",
      "Contenido: La inteligencia artificial está transformando la industria del software.\n",
      "\n",
      "ID: 4 | Título: Mercados globales | Categoría: Economía | Score: 0.7525\n",
      "Contenido: Los mercados bursátiles muestran volatilidad ante cambios geopolíticos.\n",
      "\n",
      "ID: 5 | Título: Descubrimiento espacial | Categoría: Ciencia | Score: 0.7494\n",
      "Contenido: Un nuevo telescopio detecta exoplanetas similares a la Tierra.\n",
      "\n",
      "ID: 7 | Título: Vacunas innovadoras | Categoría: Salud | Score: 0.7468\n",
      "Contenido: Se desarrollan vacunas de ARN para distintas enfermedades infecciosas.\n",
      "\n",
      "ID: 3 | Título: Aprendizaje automático | Categoría: Educación | Score: 0.7441\n",
      "Contenido: El machine learning se utiliza en plataformas educativas personalizadas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata_store = create_metadata_store(csv_path)\n",
    "\n",
    "def consulta_usuario(query_text, top_k=5, metric='cosine', embedding_dim=512):\n",
    "    \"\"\"\n",
    "    Convierte la consulta del usuario en un embedding aleatorio (simulado)\n",
    "    y devuelve los top_k documentos más similares según el metric especificado.\n",
    "    \n",
    "    Parámetros:\n",
    "    - query_text: str, texto de la consulta\n",
    "    - top_k: int, número de documentos a devolver\n",
    "    - metric: str, 'cosine' o 'euclidean'\n",
    "    - embedding_dim: dimensión de los embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    query_vector = np.random.rand(embedding_dim)\n",
    "    query_vector = query_vector / np.linalg.norm(query_vector)  \n",
    "\n",
    "    top_indices, top_scores = query_engine(np.array(embeddings), query_vector, top_k=top_k, metric=metric)\n",
    "\n",
    "    results = []\n",
    "    for idx, score in zip(top_indices, top_scores):\n",
    "        meta = metadata_store.get_metadata(idx)\n",
    "        meta['score'] = float(score)\n",
    "        results.append(meta)\n",
    "    return results\n",
    "\n",
    "\n",
    "consulta = input(\"Escribe tu consulta: \")\n",
    "resultados = consulta_usuario(consulta, top_k=5, metric='cosine')\n",
    "\n",
    "print(\"\\nDocumentos más similares:\\n\")\n",
    "for r in resultados:\n",
    "    print(f\"ID: {r['id']} | Título: {r['title']} | Categoría: {r['label']} | Score: {r['score']:.4f}\")\n",
    "    print(f\"Contenido: {r['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77981a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding simulado de la consulta: [0.0243128  0.03072299 0.01975071 0.05915896 0.05984423 0.07015604\n",
      " 0.0256633  0.07157663 0.01113393 0.00640138 0.06824134 0.00295631\n",
      " 0.05897692 0.01405346 0.01166803 0.04404628 0.03916665 0.06660361\n",
      " 0.07364459 0.02398538 0.0121638  0.06241533 0.04429045 0.04268773\n",
      " 0.06246591 0.01678022 0.02425854 0.02376129 0.02496451 0.04049475\n",
      " 0.03132388 0.05614609 0.04580093 0.0489862  0.06532018 0.03514034\n",
      " 0.02623944 0.03430231 0.00828738 0.07113374 0.01847041 0.06173907\n",
      " 0.06792487 0.01771912 0.04854409 0.06618524 0.01767381 0.00506286\n",
      " 0.02316678 0.0238674  0.00071891 0.06887295 0.01477317 0.03742872\n",
      " 0.02056687 0.00063804 0.03748704 0.04641648 0.06492509 0.06742209\n",
      " 0.01285731 0.07175478 0.03079755 0.06552276 0.05570067 0.03460577\n",
      " 0.0191483  0.00723083 0.01831884 0.04945894 0.05634269 0.04225931\n",
      " 0.04036246 0.04301334 0.05300632 0.03424647 0.0271789  0.04585473\n",
      " 0.02931685 0.03251228 0.02432429 0.0087599  0.05289064 0.05942214\n",
      " 0.05714336 0.01837269 0.04805951 0.00241859 0.02926268 0.07311588\n",
      " 0.0052403  0.0294074  0.03664894 0.02437863 0.05939491 0.05523915\n",
      " 0.03320918 0.00499021 0.00041041 0.06276014 0.00290736 0.02895716\n",
      " 0.04052798 0.03907025 0.00646242 0.05076782 0.06723851 0.04453478\n",
      " 0.05252437 0.05058042 0.028969   0.02591619 0.05220849 0.02918032\n",
      " 0.07036305 0.04827838 0.05108329 0.04458949 0.03193181 0.01486203\n",
      " 0.01441591 0.05626855 0.01864929 0.07245711 0.03216688 0.01037871\n",
      " 0.05535484 0.05861888 0.06763867 0.04549072 0.0073929  0.05780401\n",
      " 0.05344065 0.03150147 0.05988045 0.00942918 0.04113486 0.00309534\n",
      " 0.04874804 0.04125279 0.05751624 0.00179449 0.03943142 0.02588215\n",
      " 0.0618489  0.05094817 0.03993078 0.05072814 0.05395521 0.07211554\n",
      " 0.05562081 0.04610615 0.06430339 0.05121171 0.06179934 0.06775995\n",
      " 0.02192372 0.05943236 0.01438489 0.06213659 0.06232036 0.02386129\n",
      " 0.06205487 0.03191877 0.03400364 0.04890863 0.01909634 0.0683147\n",
      " 0.02164594 0.04918926 0.02421761 0.03196447 0.05512305 0.02746833\n",
      " 0.04194338 0.00727018 0.06265493 0.05487182 0.03796836 0.03246504\n",
      " 0.04054386 0.04945331 0.0714987  0.04932114 0.03563703 0.03201327\n",
      " 0.02040242 0.01015134 0.05525472 0.05309411 0.00573673 0.04579976\n",
      " 0.01504519 0.05874132 0.05440649 0.01092753 0.06334884 0.02099542\n",
      " 0.03545456 0.03050397 0.01389799 0.05111534 0.01847373 0.07186076\n",
      " 0.06891161 0.05532564 0.07340252 0.02037482 0.06232167 0.03333313\n",
      " 0.00329575 0.04652301 0.00664042 0.04902281 0.02826536 0.0520444\n",
      " 0.00259943 0.01056403 0.00998398 0.0496447  0.03780754 0.0398343\n",
      " 0.02039517 0.03646348 0.04787608 0.06813864 0.03537091 0.01498979\n",
      " 0.00854169 0.05511874 0.01467483 0.06235364 0.01358635 0.04926234\n",
      " 0.05377872 0.05792823 0.0542313  0.01222814 0.06033737 0.07276608\n",
      " 0.07058824 0.06398848 0.03702195 0.00980933 0.07129301 0.00980712\n",
      " 0.06486794 0.06828144 0.06094285 0.0358691  0.05865854 0.04893362\n",
      " 0.04321042 0.06790207 0.05880292 0.05087575 0.01546437 0.05876267\n",
      " 0.05856848 0.01295518 0.00731075 0.02050917 0.05291048 0.0684152\n",
      " 0.05790587 0.02161841 0.03542737 0.05802266 0.0647217  0.0413943\n",
      " 0.02246334 0.02645892 0.02256446 0.00538793 0.00102886 0.06182634\n",
      " 0.01516885 0.06608706 0.04999993 0.06358471 0.05062061 0.06901323\n",
      " 0.02897482 0.03625058 0.05814743 0.04657859 0.00878475 0.05872801\n",
      " 0.06320576 0.06994218 0.05455561 0.04776694 0.0264353  0.04441032\n",
      " 0.06476266 0.01724275 0.04105608 0.02119398 0.01288214 0.05842628\n",
      " 0.04437032 0.07098686 0.02798004 0.05199545 0.0061496  0.02091749\n",
      " 0.0232012  0.02937359 0.03032865 0.06567339 0.0496843  0.0211417\n",
      " 0.04890582 0.070444   0.06512153 0.00765809 0.03618248 0.05793809\n",
      " 0.07313462 0.06951508 0.01055585 0.03731053 0.01785083 0.0569738\n",
      " 0.04895906 0.04181798 0.03626476 0.06998942 0.04484802 0.07317848\n",
      " 0.05310147 0.05902251 0.02106884 0.05400298 0.02108463 0.04799658\n",
      " 0.00191184 0.02930557 0.02661094 0.03334547 0.02908431 0.04809556\n",
      " 0.00018011 0.02011391 0.04922443 0.07055425 0.03045591 0.01135728\n",
      " 0.00532571 0.00855613 0.0123105  0.059146   0.05894548 0.02832601\n",
      " 0.01460347 0.06650902 0.04701569 0.00665584 0.06786383 0.02257669\n",
      " 0.03444007 0.04553637 0.06924262 0.06164378 0.04686802 0.07357573\n",
      " 0.02432448 0.02889326 0.01930179 0.00771991 0.02274402 0.03047399\n",
      " 0.01162798 0.0450245  0.05846498 0.02325967 0.00635494 0.06616294\n",
      " 0.01606094 0.04349989 0.04768657 0.0648595  0.02261227 0.0294506\n",
      " 0.00621154 0.04070672 0.04573979 0.00845342 0.01298755 0.01467832\n",
      " 0.00175462 0.06061515 0.05706804 0.05800673 0.01528693 0.03898733\n",
      " 0.0631219  0.00507949 0.07323243 0.0422389  0.0084976  0.02540204\n",
      " 0.06729419 0.05268781 0.01963713 0.06335582 0.01420073 0.03075487\n",
      " 0.06670561 0.00625356 0.06926451 0.07162974 0.01451545 0.05591775\n",
      " 0.02386069 0.06909352 0.01747952 0.0649953  0.03471917 0.06976848\n",
      " 0.00634922 0.04570597 0.02808124 0.03064768 0.04134604 0.02491363\n",
      " 0.05441981 0.05605303 0.05352838 0.02414688 0.04698074 0.06200445\n",
      " 0.02990076 0.00248111 0.0535902  0.00083407 0.02504448 0.0443064\n",
      " 0.05606641 0.02278658 0.03221202 0.00241002 0.06292478 0.03984357\n",
      " 0.03080494 0.03701977 0.01322379 0.06911381 0.04404577 0.0431244\n",
      " 0.06054759 0.01457433 0.04368295 0.05831358 0.07094962 0.01588813\n",
      " 0.03155402 0.06675595 0.06961503 0.05093806 0.05634426 0.06481414\n",
      " 0.0201109  0.04867271 0.03056865 0.06785801 0.03409358 0.06465512\n",
      " 0.07317287 0.02554052 0.04318243 0.00319242 0.01133717 0.03559948\n",
      " 0.06536392 0.0026441  0.05565404 0.03866948 0.05162781 0.0344925\n",
      " 0.01180686 0.0114231  0.02119452 0.05823966 0.00606683 0.01927261\n",
      " 0.04279472 0.03983068 0.00272364 0.00179715 0.01103461 0.0385492\n",
      " 0.05899638 0.0312458  0.00107422 0.00285772 0.06613972 0.0344704\n",
      " 0.04848519 0.02457303 0.05432044 0.03158461 0.00472965 0.02921145\n",
      " 0.04620401 0.0109921  0.04627785 0.02409191 0.07170155 0.04004185\n",
      " 0.01130168 0.02110022]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "query_text = \"Inteligencia artificial en educación\"  # ejemplo de consulta\n",
    "query_embedding = np.random.rand(embedding_dim)      # generar embedding aleatorio\n",
    "query_embedding = query_embedding / np.linalg.norm(query_embedding)  # normalizar para coseno\n",
    "\n",
    "print(\"Embedding simulado de la consulta:\", query_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaadd4",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9280f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_por_categoria(query_text, categoria, top_k=5, metric='cosine', embedding_dim=512):\n",
    "    \"\"\"\n",
    "    Busca documentos similares a la consulta dentro de una categoría específica.\n",
    "\n",
    "    Parámetros:\n",
    "    - query_text: str, texto de la consulta\n",
    "    - categoria: str, categoría a filtrar (ej. \"Tecnología\")\n",
    "    - top_k: int, número de documentos a devolver\n",
    "    - metric: str, 'cosine' o 'euclidean'\n",
    "    - embedding_dim: dimensión de los embeddings\n",
    "    \"\"\"\n",
    "    # Simular embedding de la consulta\n",
    "    query_vector = np.random.rand(embedding_dim)\n",
    "    query_vector = query_vector / np.linalg.norm(query_vector)\n",
    "\n",
    "    # Filtramos documentos por categoría\n",
    "    indices_categoria = [i for i, label in enumerate(metadata_store.df['categoria']) if label == categoria]\n",
    "    if not indices_categoria:\n",
    "        print(f\"No se encontraron documentos en la categoría '{categoria}'\")\n",
    "        return []\n",
    "\n",
    "    # Extraemos embeddings de los documentos filtrados\n",
    "    vectors_filtrados = np.array([embeddings[i] for i in indices_categoria])\n",
    "\n",
    "    # Calcular similitudes\n",
    "    top_indices_local, top_scores = query_engine(vectors_filtrados, query_vector, top_k=top_k, metric=metric)\n",
    "\n",
    "    # Mapear de vuelta a los índices originales\n",
    "    top_indices = [indices_categoria[i] for i in top_indices_local]\n",
    "\n",
    "    # Obtener metadatos y resultados\n",
    "    results = []\n",
    "    for idx, score in zip(top_indices, top_scores):\n",
    "        meta = metadata_store.get_metadata(idx)\n",
    "        meta['score'] = float(score)\n",
    "        results.append(meta)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e98dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top documentos en la categoría 'Tecnología':\n",
      "\n",
      "ID: 6 | Título: Computación cuántica | Score: 0.7508\n",
      "Contenido: Se logran avances en la estabilidad de los qubits.\n",
      "\n",
      "ID: 1 | Título: Avances en IA | Score: 0.7498\n",
      "Contenido: La inteligencia artificial está transformando la industria del software.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Avances en inteligencia artificial\"\n",
    "categoria = \"Tecnología\"\n",
    "\n",
    "resultados = consulta_por_categoria(consulta, categoria, top_k=3, metric='cosine')\n",
    "\n",
    "print(f\"\\nTop documentos en la categoría '{categoria}':\\n\")\n",
    "for r in resultados:\n",
    "    print(f\"ID: {r['id']} | Título: {r['title']} | Score: {r['score']:.4f}\")\n",
    "    print(f\"Contenido: {r['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae3551",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1de7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def consulta_con_tiempo(query_text, categoria=None, top_k=5, metric='cosine', embedding_dim=512):\n",
    "    \"\"\"\n",
    "    Realiza la consulta y devuelve los resultados junto con el tiempo de ejecución.\n",
    "    \n",
    "    Parámetros:\n",
    "    - query_text: str, texto de la consulta\n",
    "    - categoria: str o None, filtrar por categoría si se desea\n",
    "    - top_k: int, número de documentos a devolver\n",
    "    - metric: str, 'cosine' o 'euclidean'\n",
    "    - embedding_dim: int, dimensión de los embeddings\n",
    "    \"\"\"\n",
    "    start_time = time.time()  \n",
    "\n",
    "    query_vector = np.random.rand(embedding_dim)\n",
    "    query_vector = query_vector / np.linalg.norm(query_vector)\n",
    "\n",
    "    # Filtramos por categoría si se especifica\n",
    "    if categoria:\n",
    "        indices_categoria = [i for i, label in enumerate(metadata_store.df['categoria']) if label == categoria]\n",
    "        if not indices_categoria:\n",
    "            print(f\"No se encontraron documentos en la categoría '{categoria}'\")\n",
    "            return [], 0.0\n",
    "        vectors_filtrados = np.array([embeddings[i] for i in indices_categoria])\n",
    "        top_indices_local, top_scores = query_engine(vectors_filtrados, query_vector, top_k=top_k, metric=metric)\n",
    "        top_indices = [indices_categoria[i] for i in top_indices_local]\n",
    "    else:\n",
    "        top_indices, top_scores = query_engine(embeddings, query_vector, top_k=top_k, metric=metric)\n",
    "\n",
    "    # Obtenemos metadatos\n",
    "    results = []\n",
    "    for idx, score in zip(top_indices, top_scores):\n",
    "        meta = metadata_store.get_metadata(idx)\n",
    "        meta['score'] = float(score)\n",
    "        results.append(meta)\n",
    "\n",
    "    end_time = time.time()  # Fin cronómetro\n",
    "    tiempo = end_time - start_time\n",
    "\n",
    "    return results, tiempo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a884745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo de consulta: 0.0000 segundos\n",
      "\n",
      "Documentos más similares:\n",
      "\n",
      "ID: 6 | Título: Computación cuántica | Score: 0.7442\n",
      "Contenido: Se logran avances en la estabilidad de los qubits.\n",
      "\n",
      "ID: 1 | Título: Avances en IA | Score: 0.7436\n",
      "Contenido: La inteligencia artificial está transformando la industria del software.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Avances en inteligencia artificial\"\n",
    "categoria = \"Tecnología\"  # o None para buscar en todas las categorías\n",
    "\n",
    "resultados, tiempo = consulta_con_tiempo(consulta, categoria=categoria, top_k=5, metric='cosine')\n",
    "\n",
    "print(f\"\\nTiempo de consulta: {tiempo:.4f} segundos\\n\")\n",
    "print(\"Documentos más similares:\\n\")\n",
    "for r in resultados:\n",
    "    print(f\"ID: {r['id']} | Título: {r['title']} | Score: {r['score']:.4f}\")\n",
    "    print(f\"Contenido: {r['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5a938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_metricas(query_text, categoria=None, top_k=5, embedding_dim=512):\n",
    "    \"\"\"\n",
    "    Compara resultados usando similitud coseno y distancia euclidiana.\n",
    "    \n",
    "    Retorna:\n",
    "    - resultados_cos: lista de documentos top_k usando coseno\n",
    "    - resultados_euc: lista de documentos top_k usando euclidiana\n",
    "    \"\"\"\n",
    "    # Consulta con coseno\n",
    "    resultados_cos, tiempo_cos = consulta_con_tiempo(query_text, categoria=categoria, top_k=top_k,\n",
    "                                                     metric='cosine', embedding_dim=embedding_dim)\n",
    "    \n",
    "    # Consulta con euclidiana\n",
    "    resultados_euc, tiempo_euc = consulta_con_tiempo(query_text, categoria=categoria, top_k=top_k,\n",
    "                                                     metric='euclidean', embedding_dim=embedding_dim)\n",
    "    \n",
    "    return {\n",
    "        'cosine': {'results': resultados_cos, 'tiempo': tiempo_cos},\n",
    "        'euclidean': {'results': resultados_euc, 'tiempo': tiempo_euc}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6a2abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados con Cosine ---\n",
      "ID: 1 | Título: Avances en IA | Score: 0.7570\n",
      "ID: 6 | Título: Computación cuántica | Score: 0.7359\n",
      "Tiempo: 0.0010 s\n",
      "\n",
      "--- Resultados con Euclidean ---\n",
      "ID: 1 | Título: Avances en IA | Score: 12.3565\n",
      "ID: 6 | Título: Computación cuántica | Score: 12.6018\n",
      "Tiempo: 0.0000 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Avances en inteligencia artificial\"\n",
    "categoria = \"Tecnología\"\n",
    "\n",
    "comparacion = evaluar_metricas(consulta, categoria=categoria, top_k=5)\n",
    "\n",
    "print(\"\\n--- Resultados con Cosine ---\")\n",
    "for r in comparacion['cosine']['results']:\n",
    "    print(f\"ID: {r['id']} | Título: {r['title']} | Score: {r['score']:.4f}\")\n",
    "\n",
    "print(f\"Tiempo: {comparacion['cosine']['tiempo']:.4f} s\\n\")\n",
    "\n",
    "print(\"--- Resultados con Euclidean ---\")\n",
    "for r in comparacion['euclidean']['results']:\n",
    "    print(f\"ID: {r['id']} | Título: {r['title']} | Score: {r['score']:.4f}\")\n",
    "\n",
    "print(f\"Tiempo: {comparacion['euclidean']['tiempo']:.4f} s\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b31dcd",
   "metadata": {},
   "source": [
    "Con embeddings aleatorios, la distancia euclidiana no tiene correlación semántica, solo mide separación matemática. Deberíamos utilizar TF-IDF por ejemplo para que tenga más relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85359b75",
   "metadata": {},
   "source": [
    "## SOLUCIÓN 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c3f58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hnswlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff308102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Función para búsqueda lineal (sin índice)\n",
    "# -------------------------------\n",
    "def busqueda_lineal(query_vector, top_k=5, metric='cosine'):\n",
    "    start = time.time()\n",
    "    top_indices, top_scores = query_engine(np.array(embeddings), query_vector, top_k=top_k, metric=metric)\n",
    "    tiempo = time.time() - start\n",
    "    results = [metadata_store.get_metadata(idx) for idx in top_indices]\n",
    "    return results, tiempo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de3d265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 2. Función para búsqueda usando IVF simulado\n",
    "# -------------------------------\n",
    "class IVFSearch:\n",
    "    def __init__(self, vectors, n_clusters=10):\n",
    "        self.vectors = vectors\n",
    "        self.n_clusters = n_clusters\n",
    "        self.clusters = {i: [] for i in range(n_clusters)}\n",
    "        for i, vec in enumerate(vectors):\n",
    "            cluster_id = i % n_clusters\n",
    "            self.clusters[cluster_id].append(i)\n",
    "    \n",
    "    def search(self, query_vector, top_k=5, metric='cosine'):\n",
    "        start = time.time()\n",
    "        # Determinamos cluster (simulado)\n",
    "        cluster_id = np.random.randint(0, self.n_clusters)  # en la simulación elegimos aleatorio\n",
    "        indices_cluster = self.clusters[cluster_id]\n",
    "        vectors_cluster = np.array([self.vectors[i] for i in indices_cluster])\n",
    "        top_indices_local, top_scores = query_engine(vectors_cluster, query_vector, top_k=top_k, metric=metric)\n",
    "        top_indices = [indices_cluster[i] for i in top_indices_local]\n",
    "        tiempo = time.time() - start\n",
    "        results = [metadata_store.get_metadata(idx) for idx in top_indices]\n",
    "        return results, tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c098cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Función para búsqueda usando HNSW real\n",
    "# -------------------------------\n",
    "class HNSWSearch:\n",
    "    def __init__(self, vectors, ef_construction=200, M=16):\n",
    "        self.dim = vectors.shape[1]\n",
    "        self.index = hnswlib.Index(space='l2', dim=self.dim)\n",
    "        self.index.init_index(max_elements=vectors.shape[0], ef_construction=ef_construction, M=M)\n",
    "        self.index.add_items(vectors)\n",
    "        self.index.set_ef(50)  # para búsqueda\n",
    "        self.vectors = vectors\n",
    "    \n",
    "    def search(self, query_vector, top_k=5):\n",
    "        start = time.time()\n",
    "        labels, distances = self.index.knn_query(query_vector, k=top_k)\n",
    "        tiempo = time.time() - start\n",
    "        results = [metadata_store.get_metadata(idx) for idx in labels[0]]\n",
    "        return results, tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9ca0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo búsqueda lineal: 0.000000 s\n",
      "Tiempo búsqueda IVF: 0.002571 s\n",
      "Tiempo búsqueda HNSW: 0.000000 s\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Comparación de tiempos\n",
    "# -------------------------------\n",
    "\n",
    "embedding_dim = embeddings.shape[1]\n",
    "query_vector = np.random.rand(embedding_dim)\n",
    "query_vector = query_vector / np.linalg.norm(query_vector)\n",
    "\n",
    "# Sin índice\n",
    "res_lineal, t_lineal = busqueda_lineal(query_vector)\n",
    "# Con IVF\n",
    "ivf_search = IVFSearch(embeddings, n_clusters=10)\n",
    "res_ivf, t_ivf = ivf_search.search(query_vector)\n",
    "# Con HNSW\n",
    "hnsw_search = HNSWSearch(embeddings)\n",
    "res_hnsw, t_hnsw = hnsw_search.search(query_vector)\n",
    "\n",
    "print(f\"Tiempo búsqueda lineal: {t_lineal:.6f} s\")\n",
    "print(f\"Tiempo búsqueda IVF: {t_ivf:.6f} s\")\n",
    "print(f\"Tiempo búsqueda HNSW: {t_hnsw:.6f} s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
