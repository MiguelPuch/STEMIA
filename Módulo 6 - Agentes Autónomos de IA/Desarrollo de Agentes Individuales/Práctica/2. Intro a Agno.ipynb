{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf41e3f",
   "metadata": {},
   "source": [
    "# Agno\n",
    "\n",
    "[Agno](agno.com) es un framework que pretende aligerar la forma en la que otros frameworks nos obligan a trabajar para crear nuestros agentes. Simplifica gran parte del código a generar centrándose en los aspectos clave. Ofrece una plataforma donde a futuro será posible gestionar nuestros agentes y flujos de trabajo (https://app.agno.com/) aunque de momento lo podemos emplear como framework local. Dispone de multitud de ejemplos en la [documentación](https://docs.agno.com/).\n",
    "\n",
    "![](https://mintcdn.com/agno/QZOB15dhrj4yAmBd/images/workspace.png?w=840&maxW=3034&auto=format&n=QZOB15dhrj4yAmBd&q=85&s=192feab94035c340f257f7b7f228cd19)\n",
    "\n",
    "Podemos levantar todo un workspace local con ejemplos siguiendo los pasos en: https://docs.agno.com/workspaces/introduction\n",
    "\n",
    "Aunque para estos ejemplos iremos paso a paso, empezando con la importación de las claves de conexión y algunos parámetros básicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19159e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef34348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70572aca0cc4d44872fa15d571ca8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "\n",
    "# Create a News Reporter Agent with a fun personality\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"Eres un asistente de matemáticas.\",\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "agent.print_response(\n",
    "    \"Hola, ¿puedes ayudarme con unos cálculos?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58bac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edee8d311d6483b96e1ec1a465ce92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\n",
    "    \"¿Cuanto es 4 * 5?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f18bd3",
   "metadata": {},
   "source": [
    "Al igual que LangChain podemos trazar la actividad pero veréis que en este caso es algo menos visual en [LangSmith via OpenTelemetry](https://docs.agno.com/examples/concepts/observability/langsmith-via-openinference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d79cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "# Set the endpoint and headers for LangSmith\n",
    "endpoint = \"https://api.smith.langchain.com/otel/v1/traces\"\n",
    "headers = {\n",
    "    \"x-api-key\": os.getenv(\"LANGSMITH_API_KEY\"),\n",
    "    \"Langsmith-Project\": os.getenv(\"LANGSMITH_PROJECT\"),\n",
    "}\n",
    "\n",
    "# Configure the tracer provider\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(\n",
    "    SimpleSpanProcessor(OTLPSpanExporter(endpoint=endpoint, headers=headers))\n",
    ")\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "\n",
    "# Start instrumenting agno\n",
    "AgnoInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6aa04",
   "metadata": {},
   "source": [
    "Podemos extender el uso de herramientas tal y como vimos con LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b18bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669ddb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f03137b7f594798915ac309ed5286ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a News Reporter Agent with a fun personality\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"Eres un asistente de matemáticas.\",\n",
    "    tools=[multiply],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "agent.print_response(\n",
    "    \"¿Cuanto es 4 * 5?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45a0ed",
   "metadata": {},
   "source": [
    "Podemos incluir herramientas más elaboradas como los buscadores web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a33c3e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d22ca3ca6749398d7c842772fede54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.tools.tavily import TavilyTools\n",
    "\n",
    "# Search engine\n",
    "search = TavilyTools()\n",
    "\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"\"\"\n",
    "        Eres un especialista en viajes trabajando en una agencia. \n",
    "        Tu trabajo es proponer opciones de viajes a los clientes aunque tienes una predilección por Bilbao y siempre que puedes lo propones como destino.\"\"\",\n",
    "    tools=[search],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "agent.print_response(\n",
    "    \"¿Qué viajes hay a Madrid desde Santander?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fcf6c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bb78f427d4409280d16ffe3dd12356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\n",
    "    \"Está bien, busca entonces vuelos a ese destino\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9dad5",
   "metadata": {},
   "source": [
    "Acordémonos de que los agentes no tienen memoria. Necesitamos indicarle cuantos mensajes debe recordar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba0cfd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4a0e1ecbb840779339b7b81ccb7481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"\"\"\n",
    "        Eres un especialista en viajes trabajando en una agencia. \n",
    "        Tu trabajo es proponer opciones de viajes a los clientes aunque tienes una predilección por Bilbao y siempre que puedes lo propones como destino.\"\"\",\n",
    "    tools=[search],\n",
    "    # Memoria\n",
    "    add_history_to_messages=True,\n",
    "    num_history_responses=3,\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "agent.print_response(\n",
    "    \"Estoy en Santander ¿Qué viajes hay a Madrid?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7745e943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd05253a6f741f29b6955cea10306b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\n",
    "    \"Está bien, busca entonces vuelos a ese destino desde mi ciudad\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82026c99",
   "metadata": {},
   "source": [
    "En muchos casos necesitaremos que nuestro interlocutor nos de el ok a la operación. Para eso, debemos instruir al agente de que la ejecución de la herramienta debe disponer de una aceptación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb8f50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Callable, Dict, Iterator\n",
    "\n",
    "import httpx\n",
    "from agno.exceptions import StopAgentRun\n",
    "from agno.tools import tool\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "# Consola\n",
    "console = Console()\n",
    "\n",
    "# Confirmation hook\n",
    "def confirmation_hook(\n",
    "    function_name: str, function_call: Callable, arguments: Dict[str, Any]\n",
    "):\n",
    "    # Get the live display instance from the console\n",
    "    live = console._live\n",
    "\n",
    "    # Stop the live display temporarily so we can ask for user confirmation\n",
    "    live.stop()  # type: ignore\n",
    "\n",
    "    # Ask for confirmation\n",
    "    console.print(f\"\\nVoy a ejecutar [bold blue]{function_name}[/]\")\n",
    "    message = (\n",
    "        Prompt.ask(\"¿Quieres que proceda?\", choices=[\"s\", \"n\"], default=\"s\")\n",
    "        .strip()\n",
    "        .lower()\n",
    "    )\n",
    "\n",
    "    # Restart the live display\n",
    "    live.start()  # type: ignore\n",
    "\n",
    "    # If the user does not want to continue, raise a StopExecution exception\n",
    "    if message != \"s\":\n",
    "        raise StopAgentRun(\n",
    "            \"Tool call cancelled by user\",\n",
    "            agent_message=\"Stopping execution as permission was not granted.\",\n",
    "        )\n",
    "    \n",
    "    # Call the function\n",
    "    result = function_call(**arguments)\n",
    "\n",
    "    # Optionally transform the result\n",
    "\n",
    "    return result\n",
    "\n",
    "# A tool that requests confirmation\n",
    "@tool(tool_hooks=[confirmation_hook])\n",
    "def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:\n",
    "    \"\"\"Fetch top stories from Hacker News.\n",
    "\n",
    "    Args:\n",
    "        num_stories (int): Number of stories to retrieve\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string containing story details\n",
    "    \"\"\"\n",
    "    # Fetch top story IDs\n",
    "    response = httpx.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\")\n",
    "    story_ids = response.json()\n",
    "\n",
    "    # Yield story details\n",
    "    final_stories = []\n",
    "    for story_id in story_ids[:num_stories]:\n",
    "        story_response = httpx.get(\n",
    "            f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\"\n",
    "        )\n",
    "        story = story_response.json()\n",
    "        if \"text\" in story:\n",
    "            story.pop(\"text\", None)\n",
    "        final_stories.append(story)\n",
    "\n",
    "    return json.dumps(final_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb061d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeb76d55fe84b52a8a7abc2c09ee403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Voy a ejecutar <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">get_top_hackernews_stories</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Voy a ejecutar \u001b[1;34mget_top_hackernews_stories\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">¿Quieres que proceda? <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[s/n]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(s)</span>: </pre>\n"
      ],
      "text/plain": [
       "¿Quieres que proceda? \u001b[1;35m[s/n]\u001b[0m \u001b[1;36m(s)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "\n",
    "# Create an Agent\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"Eres un especialista en periodismo tecnológico y puedes predecir tendencias de mercado basado en noticias de hackernews.\",\n",
    "    tools=[get_top_hackernews_stories],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "agent.print_response(\n",
    "    \"¿Qué disrupciones prevés para este final de año?\", stream=True, console=console\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cf201",
   "metadata": {},
   "source": [
    "## Retrieve-Augmented Generation (RAG)\n",
    "\n",
    "Más allá de las herramientas, uno de los pasos clave es cuando podemos introducir información curada o específica de nuestro dominio. Debemos encontrar la mejor forma de hacerlo pero podemos disponer de bases de datos que nos permitan facilitar era búsqueda y que la información obtenida sea parte de nuestra consulta. Este mecanismo es el conocido como RAG. El equipo de Pinecone, una de las primeras bases de datos vectoriales en su momento, tiene una [entrada de blog](https://www.pinecone.io/learn/retrieval-augmented-generation/) bastante aclaratoria de los sistemas RAG.\n",
    "\n",
    "![](https://www.pinecone.io/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Ff6fe392bb5287791a2c6052f1eeb3072ad0b7e36-2236x2620.png&w=3840&q=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854d245",
   "metadata": {},
   "source": [
    "Dependiendo del tipo de pregunta que vayamos a hacer podemos necesitar un sistema distinto al que habitualmente tenemos (RDBMS):\n",
    "\n",
    "* Para búsquedas difusas o resumen de una temática, precisaremos buscar textos que hablen de esta por **similitud semántica**.\n",
    "* A veces necesitamos la ocurrencia exacta de términos, y esto podemos hacerlo mediante **filtros explícitos**.\n",
    "\n",
    "En otros casos necesitaremos conocer la estructura vinculada de los textos (legal) o jerarquía de forma que textos que no hablan del mismo concepto o no presentan términos concretos habiliten distintas acepciones. De ahí que Microsoft propusiera en [2024 el GraphRAG](https://microsoft.github.io/graphrag/) basado en bases de datos en grafos.\n",
    "\n",
    "La gran tarea de estos sistemas es precisamente modelar la información para poder luego interrogarla. En el caso de bases de datos vectoriales:\n",
    "\n",
    "* **seccionado de la información** https://www.pinecone.io/learn/chunking-strategies/\n",
    "* **embedding**\n",
    "* **establecer el modelo de búsqueda** mediante búsqueda semántica y lexicológica lo que conocemos como búsqueda híbrida (https://docs.pinecone.io/guides/search/hybrid-search)\n",
    "\n",
    "Quizás por ser los primeros en el mercado tiene una posición predominante aunque otros proveedores (LanceDB, Chroma, Qdrant, etc.) presentan una oferta similar. Podéis ver los sistemas más usados en https://db-engines.com/en/ranking_trend/vector+dbms\n",
    "\n",
    "Desde el punto de vista académico, Facebook con [FAISS](https://faiss.ai/) fue una de las primeras empresas en plantear este tipo de búsqueda de información.\n",
    "\n",
    "En el ejemplo de abajo emplearemos [LanceDB](https://www.lancedb.com/) que está disponible tanto en formato on-premise como cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "236dbb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating table: langchain                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating table: langchain                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-09-04T07:35:01Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /home/iraitz/TheBridge/B2B/DS4B2B/M5 - Aplicaciones de GenAI/lancedb/langchain.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "from agno.embedder.google import GeminiEmbedder\n",
    "from agno.vectordb.lancedb import LanceDb, SearchType\n",
    "from agno.knowledge.markdown import MarkdownKnowledgeBase\n",
    "\n",
    "# Database\n",
    "vector_db = LanceDb(\n",
    "    table_name=\"langchain\",\n",
    "    uri=\"./lancedb\",  # You can change this path to store data elsewhere\n",
    "    embedder=GeminiEmbedder(),\n",
    "    use_tantivy=True\n",
    ")\n",
    "\n",
    "# Knowledge base\n",
    "knowledge_base = MarkdownKnowledgeBase(\n",
    "    path=\"./markdown_files\",\n",
    "    vector_db=vector_db,\n",
    "    search_type=SearchType.hybrid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52a945",
   "metadata": {},
   "source": [
    "Las consultas pueden hacerse tanto por el texto que contienen de cara a buscar las palabras clave, como por el embedding generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3fef903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.025601903,\n",
       " -0.015883127,\n",
       " -0.006648923,\n",
       " -0.057227448,\n",
       " -0.007338925,\n",
       " 0.021304669,\n",
       " -0.00434841,\n",
       " 0.010607597,\n",
       " -0.0051602297,\n",
       " 0.030773513]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = \"What are agents?\"\n",
    "\n",
    "query = {\n",
    "    \"text\" : query_text,\n",
    "    \"vector\" : GeminiEmbedder().get_embedding(query_text)\n",
    "}\n",
    "query['vector'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a4526",
   "metadata": {},
   "source": [
    "Como en cualquier proceso ETL, deberemos cargar la información primero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9a5ddd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: markdown_files/agents.md                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: markdown_files/agents.md                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m3\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knowledge_base.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf578d4",
   "metadata": {},
   "source": [
    "Y ahora definir un agente enlazado a esa base de conocimiento. Otros sistemas con algo más complejos pero Agno nos ofrece una integración sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3a5dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f607080221e444369311093e9cb5b745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m3\u001b[0m documents                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "\n",
    "# Create an Agent\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    knowledge=knowledge_base,\n",
    "    tools=[search],\n",
    "    # search_knowledge=True gives the Agent the ability to search on demand\n",
    "    # search_knowledge is True by default\n",
    "    search_knowledge=True,\n",
    "    instructions=[\n",
    "        \"Include sources in your response.\",\n",
    "        \"Always search your knowledge before answering the question.\",\n",
    "        \"Only include the output in your response. No other text.\",\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    "    add_references=True,\n",
    ")\n",
    "\n",
    "agent.print_response(\"What are agents?\", stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468281a",
   "metadata": {},
   "source": [
    "## Multimodelo\n",
    "\n",
    "Algunas plataformas operacionales se han liado la manta al la cabeza y nos ofrecen sistemas multimodelo que puedan cubrir con todas nuestras necesidades. Este es el caso de [SurrealDB](https://surrealdb.com/) que recientemente ofrece búsqueda basadas en vectores y está integrada con nuestro framework de forma nativa: https://docs.agno.com/vectordb/surrealdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24b14014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from surrealdb import Surreal\n",
    "\n",
    "# SurrealDB connection parameters\n",
    "SURREALDB_URL = os.getenv(\"SURREAL_HOST\")\n",
    "SURREALDB_USER = os.getenv(\"SURREAL_USER\")\n",
    "SURREALDB_PASSWORD = os.getenv(\"SURREAL_PASS\")\n",
    "SURREALDB_NAMESPACE = os.getenv(\"SURREAL_NAMESPACE\")\n",
    "SURREALDB_DATABASE = os.getenv(\"SURREAL_DB\")\n",
    "\n",
    "# Create a client\n",
    "client = Surreal(url=SURREALDB_URL)\n",
    "client.signin({\"username\": SURREALDB_USER, \"password\": SURREALDB_PASSWORD})\n",
    "client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc165a1c",
   "metadata": {},
   "source": [
    "Dado el esquema multimodelo y versátil que proporciona SurrealDB, podemos realizar búsquedas complejas que tienen en cuenta tanto la cercanía semántica como la relación en grafo entre fragmentos. El algoritmo Hierarchical Navigable Small World (HNSW) es una técnica basada en grafos para la búsqueda aproximada de vecinos más cercanos utilizada en muchas bases de datos vectoriales. La búsqueda de vecinos más cercanos sin un índice implica calcular la distancia de la consulta a cada punto de la base de datos, lo que, para conjuntos de datos grandes, resulta computacionalmente prohibitivo.\n",
    "\n",
    "https://www.pinecone.io/learn/series/faiss/hnsw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5be13e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Dropping collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Dropping collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf</span>                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: \u001b[4;94mhttps://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\u001b[0m                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> documents to knowledge base                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m14\u001b[0m documents to knowledge base                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.vectordb.surrealdb import SurrealDb\n",
    "from agno.embedder.google import GeminiEmbedder\n",
    "from agno.knowledge.pdf_url import PDFUrlKnowledgeBase\n",
    "\n",
    "# Database\n",
    "surrealdb = SurrealDb(\n",
    "    client=client,\n",
    "    collection=\"recetas\",  # Collection name\n",
    "    efc=150,  # HNSW construction time/accuracy trade-off\n",
    "    m=12,  # HNSW max number of connections per element\n",
    "    search_ef=40,  # HNSW search time/accuracy trade-off\n",
    "    embedder=GeminiEmbedder(),\n",
    ")\n",
    "\n",
    "# Knowledge base\n",
    "knowledge_base = PDFUrlKnowledgeBase(\n",
    "    urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n",
    "    vector_db=surrealdb\n",
    ")\n",
    "knowledge_base.load(recreate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3715379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce6e1d0ae3b4b4ebb96fabe2208cd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "\n",
    "# Create agent and query synchronously\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    knowledge=knowledge_base,\n",
    "    show_tool_calls=True\n",
    ")\n",
    "agent.print_response(\n",
    "    \"Cuales son las tres categorías que Thai SELECT establece?\",\n",
    "    markdown=True,\n",
    "    stream=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4b2b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
