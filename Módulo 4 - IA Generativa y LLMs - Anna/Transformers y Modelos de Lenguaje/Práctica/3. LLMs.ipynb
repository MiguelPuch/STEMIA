{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Models (LLMs)\n",
    "\n",
    "Los large language models o LLMs son estructuras de redes neuronales pensadas especialmente para la generación del lenguaje.\n",
    "\n",
    "Heredan mucha de la tarea anteriormente realizada que ha terminado siendo condensada en lo que conocemos como Transformers.\n",
    "\n",
    "Entender la estructura de estos modelos es clave para poder saber de sus posibilidades y limitaciones. Una pieza clave del proceso es el mecanismo de atención y los bloques _transformers_ compuestos de tres piezas que podemos entender en el contexto de los buscadores (para ejemplificarlo) a pesar de que no son más que tres representaciones vectoriales con sus pesos a aprender asociados:\n",
    "\n",
    "* La **consulta** (Q o query) que es el texto de búsqueda que se escribe en la barra de búsqueda. Este es el token sobre el que desea \"encontrar más información\".\n",
    "* La **clave** (K o key) es el título de cada página web en la ventana de resultados de búsqueda. Representa los posibles tokens a los que puede prestar atención la consulta.\n",
    "* El **valor** (V) es el contenido real de las páginas web mostradas. Una vez que hemos hecho coincidir el término de búsqueda apropiado (Consulta) con los resultados relevantes (Clave), queremos obtener el contenido (Valor) de las páginas más relevantes.\n",
    "\n",
    "El concepto de multi-headed se debe a que el mecanismo de atención que presentan estas tres claves puede ser procesado de forma parcial por multiples unidades para captar distintas relacionalidades o puntos de _atención_ sobre el texto.\n",
    "\n",
    "La arquitectura base de los transformers puede verse en su artículo original _Attention is all you need_ [aquí](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "\n",
    "![](../assets/images/Transformers.png)\n",
    "\n",
    "Los siguientes recursos pueden ayudarnos a entender más en profundidad estos modelos que de algún modo combinan muchos de los conceptos vistos previamente (arquitectura encdoer-decoder, embeddings y generación condicionada):\n",
    "\n",
    "* Explicación detallada: https://poloclub.github.io/transformer-explainer/\n",
    "* Visualizador: https://bbycroft.net/llm\n",
    "\n",
    "Deberemos entender bien lo que significa la **temperatura** y el **contexto** en estos modelos. El contexto es el máximo número de tokens que puede procesar de una sola vez. Esto es importante porque las LLMs no tienen memoria, con lo cual el límite del contexto determina cuanta información de nuestra conversación les será servida:\n",
    "\n",
    "* GPT-3: 2048 tokens\n",
    "* Mistral 7B: 8192 tokens\n",
    "* GPT-4o: De 60K a 128K tokens\n",
    "* Claude 3.5: Hasta 100K tokens\n",
    "* LLama 3.1: Hasta 128K tokens\n",
    "* Gemini 1.5 Pro: Hasta 1M tokens\n",
    "\n",
    "Podemos ver y jugar con estos parámetros usando los servicios de playground:\n",
    "\n",
    "- OpenAI Playground: https://platform.openai.com/playground/prompts\n",
    "- Google AI Studio: https://aistudio.google.com/prompts/new_chat\n",
    "- Anthopic Console: https://console.anthropic.com/dashboard\n",
    "\n",
    "## ¿Qué es ChatGPT?\n",
    "\n",
    "Digamos que se trata de un _sabor_ de LLM. Quizás uno de los más populares. GPT, el modelo de LLM tras la aplicación ChatGPT, es un modelo de lenguaje desarrollado por [OpenIA](https://openai.com/).\n",
    "\n",
    "### Historia de versiones\n",
    "\n",
    "- GPT (2018): 117 millones de parámetros\n",
    "- GPT-2 (2019): 1.5 miles de millones de parámetros. \n",
    "- GPT-3 (2020) -> llegada de chatGPT: 175 miles de millones de parámetros. \n",
    "- GPT-3.5 (2022) \n",
    "- [GPT-4](https://openai.com/product/gpt-4) (2023): 100 Billones de parámetros. \n",
    "- [GPT-4o](https://en.wikipedia.org/wiki/GPT-4o) (2024)\n",
    "- [o3](https://en.wikipedia.org/wiki/OpenAI_o3) (2025)\n",
    "\n",
    "Existen multitud de modelos a día de hoy, algunos con acceso a sus pesos lo cual marca un hito en la competencia que se realizan entre sí, a pesar de que debido al tamaño de estos modelos es difícil realizar despliegues on-premise sin tener una buena infraestructura pensada para ello.\n",
    "\n",
    "![llm](../assets/images/1721759844068.jpeg)\n",
    "\n",
    "## Cómo funcionan los LLMs\n",
    "\n",
    "En esencia, los LLMs calculan las probabilidades de que cierta palabra siga a una cadena de palabras dada previamente. Para ello, se nutren de corpus o conjuntos de datos muy grandes, como toda la Wikipedia en inglés o un subconjunto representativo de las páginas de internet.\n",
    "\n",
    "El LLM \"guarda\" las sucesiones de palabras que ha encontrado en su entrenamiento y a partir de ahí asignará probabilidades a las siguientes palabras, dada una cadena de palabras previa que usa como punto de partida (el prompt). A esta fase se le llama pre-entrenamiento por su role en establecer el contexto para el resto de soluciones. Muchos de estos modelos explotan arquitecturas basadas en el modelo de Transformers.\n",
    "\n",
    "Os recomendamos la documentación de HuggingFace respecto a este tema: https://huggingface.co/learn/nlp-course/es/chapter1/4\n",
    "\n",
    "## Aplicaciones de los LLMs\n",
    "\n",
    "Los LLMs brindan una amplia variedad de aplicaciones debido a su capacidad para comprender y generar lenguaje humano. Algunas de las aplicaciones más destacadas son:\n",
    "\n",
    "- **Generación de texto**: Los LLMs pueden generar contenido coherente y de alta calidad en una variedad de contextos, como redacción de artículos, resúmenes automáticos y creación de código.\n",
    "- **Respuesta a preguntas**: Los LLMs pueden responder preguntas de forma conversacional, interpretando la intención del usuario y respondiendo a comandos sofisticados.\n",
    "- **Traducción de idiomas**: Los LLMs pueden traducir texto de un idioma a otro, facilitando la comunicación intercultural.\n",
    "- **Análisis de datos**: Los LLMs pueden revisar grandes cantidades de datos de texto para extraer información de diversas fuentes y ayudar a las empresas a tomar decisiones bien fundamentadas.\n",
    "\n",
    "## Limitaciones y desafíos de los LLMs\n",
    "\n",
    "Si bien los LLMs ofrecen muchas ventajas, también tienen algunas limitaciones y desafíos a considerar:\n",
    "\n",
    "- **Coste**: Se necesita una gran cantidad de recursos para desarrollar, entrenar e implementar los LLMs.\n",
    "- **Privacidad y seguridad**: Los LLMs requieren acceso a mucha información, incluyendo en ocasiones datos de clientes o empresas, lo que debe manejarse con cuidado.\n",
    "- **Precisión y sesgo**: Los LLMs pueden incorporar información incorrecta o sesgada presente en los datos de entrenamiento, generando respuestas que no reflejan la realidad.\n",
    "\n",
    "En resumen, los Large Language Models (LLMs) son modelos de aprendizaje automático que pueden realizar una amplia gama de tareas de procesamiento del lenguaje natural gracias a su capacidad de comprender y generar lenguaje humano. Sin embargo, también presentan desafíos en cuanto a costo, privacidad, sesgo y precisión que deben ser abordados adecuadamente.\n",
    "\n",
    "Veremos unos ejemplos de cómo podéis emplear modelos \"abiertos\". Quizás uno de los más populares, Llama de Meta, nos exige que tengamos suficiente capacidad para ejecutar un modelo de al menos 8 billones de parámetros pere puede ser útil para tener una instalación local. Deberéis contar con una cuenta en HuggingFace https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade python-dotenv huggingface tf-keras transformers  torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podéis crear un fichero _.env_ y guardar el token que encontraréis en vuestro perfil de HuggingFace para poder acceder a la solución.\n",
    "\n",
    "```\n",
    "TOKEN_HF=hf_...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iraitz/TheBridge/B2B/DS4B2B/.venv_tf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token = os.environ.get(\"TOKEN_HF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vais a utilizar algún modelo concreto, prestad atención a los términos y condiciones de uso. Llama, por ejemplo, requiere que aceptéis los términos y tarda en dar acceso.\n",
    "\n",
    "![accept](../assets/images/llama.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que estos modelos pueden tener unos requisitos muy pesados, podemos emplear una versión ligera que quizás no sea tan \"inteligente\". Es cuestión de elegir el modelo que más os encaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué palabra sugiere a continuación... Podemos mirar en la documentación las opciones que nos ofrecen los pipelines: https://huggingface.co/docs/transformers/v4.43.2/en/main_classes/pipelines#pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Llama is an open source irc'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Llama is an open source \", max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Llama is an open source \\xa0tutorial'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Llama is an open source \", max_new_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Llama is an open source vernacular for Linux and'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Llama is an open source \", max_new_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Llama is an open source irc server. It utilizes the open source OpenSSL library to encrypt data on all public and private networks'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Llama is an open source \", max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los primeros efectos que notaremos es que la LLM está limitada por su corte de conocimiento, la fecha en la que fué entrenada (2019) y el acceso a información que tuviera en general: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "En lugar de hospedar los modelos podemos optar por usar los servicios desplegados, lo cuál os requerirá disponer de una cuenta de pago y así poder obtener el token de acceso al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "Otras opciones populares son el consumo de los servicios en su modalidad REST. Es decir, el modelo no estará cargado en nuestro sistema si no que lo invocaremos a servicios externos como es el caso de OpenAI y sus modelos:\n",
    "\n",
    "* Generative Pre-trained Transformer (GPT)\n",
    "* DALLE: https://arxiv.org/abs/2102.12092\n",
    "* SORA: https://openai.com/index/sora/\n",
    "\n",
    "https://platform.openai.com/apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder conectarnos podemos emplear el interfaz que ellos mismos proveen (https://platform.openai.com/playground/chat?models=gpt-3.5-turbo) o conectarnos desde nuestro entorno Python, para lo que necesitaremos un token de acceso.\n",
    "\n",
    "![gpt](../assets/images/openai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los roles nos ayudan a establecer el condicionamiento del sistema a la hora de responser preguntas. `system` hace referencia al contexto de cómo responder, mientras que `user` es la consulta que realiza en usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el vasto mundo del aprendizaje automático,\n",
      "La regularización brilla con fulgor sutil y acierto,\n",
      "Un guardián que controla la complejidad con tino,\n",
      "Evitando que el modelo se pierda en el abismo.\n",
      "\n",
      "Lasso y Ridge, dos leales compañeros,\n",
      "Penalizan los coeficientes con esmero,\n",
      "Restringiendo su tamaño con maestría,\n",
      "Para evitar el overfitting con armonía.\n",
      "\n",
      "La regularización, en su sabiduría,\n",
      "Busca encontrar el equilibrio con maestría,\n",
      "Entre el sesgo y la varianza, en perfecta armonía,\n",
      "Para que el modelo brille con valentía.\n",
      "\n",
      "Así, en el mar de datos y predicciones,\n",
      "La regularización guía con decisiones,\n",
      "Protegiendo al modelo de sus propias ambiciones,\n",
      "Y asegurando resultados con precisión.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_TOKEN\"))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are the best poetic assistant, skilled in explaining complex programming concepts with creative flair. Write it in Spanish.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept regularization in Machine learning.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "Por debajo, estos textos han sido convertidos a la codificación (embedding) necesaria. Vemos un ejemplo de qué pinta tiene, por ejemplo, para cuando queremos añadir nuestra información particular al corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...      5.0   \n",
       "1  The product does exactly as it should and is q...      5.0   \n",
       "2  The primary job of this device is to block the...      5.0   \n",
       "3  Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4  This pop filter is great. It looks and perform...      5.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_URL =  \"https://raw.githubusercontent.com/keitazoumana/Experimentation-Data/main/Musical_instruments_reviews.csv\"\n",
    "\n",
    "review_df = pd.read_csv(data_URL)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa el texto de review para ver qué opinion se arrojó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (10261, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  Not much to write about here, but it does exac...\n",
       "1  The product does exactly as it should and is q...\n",
       "2  The primary job of this device is to block the...\n",
       "3  Nice windscreen protects my MXL mic and preven...\n",
       "4  This pop filter is great. It looks and perform..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_df = review_df[['reviewText']]\n",
    "print(\"Data shape: {}\".format(review_df.shape))\n",
    "display(review_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este texto es el que primeramente deberemos convertir a números si queremos que sea procesado por nuestro modelo de IA. Veamos qué embeddings arroja OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04324784129858017,\n",
       " -0.029252413660287857,\n",
       " -0.017573131248354912,\n",
       " 0.009772159159183502,\n",
       " -0.01015161257237196,\n",
       " -0.020362360402941704,\n",
       " 0.008067082613706589,\n",
       " 0.01195524912327528,\n",
       " -0.03248516097664833,\n",
       " -0.04888543486595154,\n",
       " -0.02751776948571205,\n",
       " 0.0010428810492157936,\n",
       " -0.029075007885694504,\n",
       " -0.033628448843955994,\n",
       " 0.008939333260059357,\n",
       " 0.05385282635688782,\n",
       " -0.07490510493516922,\n",
       " 0.01162014715373516,\n",
       " -0.022609515115618706,\n",
       " 0.0282076857984066,\n",
       " 0.049121979624032974,\n",
       " -0.02749805711209774,\n",
       " -0.03317507728934288,\n",
       " 0.02540859952569008,\n",
       " 0.025881685316562653,\n",
       " -0.000267188239376992,\n",
       " 0.024245599284768105,\n",
       " -0.017208462581038475,\n",
       " -0.018213767558336258,\n",
       " 0.004341539461165667,\n",
       " 0.06351163983345032,\n",
       " -0.03603329882025719,\n",
       " 0.008032586425542831,\n",
       " 0.027576904743909836,\n",
       " -0.03108561784029007,\n",
       " 0.0046766409650444984,\n",
       " -0.00883584562689066,\n",
       " 0.020204667001962662,\n",
       " 0.002358032390475273,\n",
       " -0.01587790995836258,\n",
       " 0.030573109164834023,\n",
       " -0.011610290966928005,\n",
       " 0.01794765703380108,\n",
       " 0.03895065560936928,\n",
       " -0.011038647033274174,\n",
       " -0.008939333260059357,\n",
       " -0.03630926460027695,\n",
       " -0.011206197552382946,\n",
       " 0.04411516338586807,\n",
       " 0.03315536305308342,\n",
       " -0.003681191708892584,\n",
       " 0.010634553618729115,\n",
       " 0.0348505862057209,\n",
       " 0.1561180055141449,\n",
       " 0.06914924085140228,\n",
       " -0.02460041269659996,\n",
       " 0.018962819129228592,\n",
       " 0.02637448161840439,\n",
       " -0.004841728135943413,\n",
       " 0.005637594498693943,\n",
       " -0.028582211583852768,\n",
       " -0.014340384863317013,\n",
       " 0.02292490378022194,\n",
       " 0.025526870042085648,\n",
       " 0.007318031508475542,\n",
       " -0.010683833621442318,\n",
       " -0.036269839853048325,\n",
       " 0.0055981711484491825,\n",
       " -0.0175534188747406,\n",
       " -0.013532198034226894,\n",
       " -0.04837292805314064,\n",
       " 0.03883238136768341,\n",
       " 0.011758130043745041,\n",
       " -0.012043952010571957,\n",
       " -0.0003520416794344783,\n",
       " 0.016942352056503296,\n",
       " 0.016390418633818626,\n",
       " -0.03634868562221527,\n",
       " 0.020244089886546135,\n",
       " -0.013492774218320847,\n",
       " -0.07557530701160431,\n",
       " 0.003077515633776784,\n",
       " -0.025172056630253792,\n",
       " -0.010565562173724174,\n",
       " 0.0021535216365009546,\n",
       " 0.00290503678843379,\n",
       " -0.0052778529934585094,\n",
       " 0.017789961770176888,\n",
       " -0.016331283375620842,\n",
       " -0.028266821056604385,\n",
       " -0.004366178996860981,\n",
       " 0.040409334003925323,\n",
       " -0.06591649353504181,\n",
       " 0.00010610529716359451,\n",
       " 0.022432107478380203,\n",
       " -0.02416675165295601,\n",
       " -0.009244866669178009,\n",
       " 0.04115838184952736,\n",
       " 0.02556629478931427,\n",
       " -0.017040912061929703,\n",
       " 0.061934694647789,\n",
       " -0.007056849077343941,\n",
       " 0.016084885224699974,\n",
       " -0.019928699359297752,\n",
       " 0.04979218170046806,\n",
       " -0.02264893800020218,\n",
       " -0.023299429565668106,\n",
       " -0.012457901611924171,\n",
       " 0.0009166019153781235,\n",
       " -0.05531150475144386,\n",
       " -0.01892339438199997,\n",
       " -0.04423343390226364,\n",
       " 0.023397989571094513,\n",
       " -0.0006153799477033317,\n",
       " 0.015286554582417011,\n",
       " -0.002949388464912772,\n",
       " 0.05310377478599548,\n",
       " -0.019544318318367004,\n",
       " 0.027320651337504387,\n",
       " -0.0364866703748703,\n",
       " -0.0034002973698079586,\n",
       " -0.023023463785648346,\n",
       " 0.030080312862992287,\n",
       " 0.007076560985296965,\n",
       " -0.07163293659687042,\n",
       " 0.014813469722867012,\n",
       " 0.012871851213276386,\n",
       " 0.028385091572999954,\n",
       " -0.017198605462908745,\n",
       " 0.009629248641431332,\n",
       " 0.008732357993721962,\n",
       " 0.026059091091156006,\n",
       " -0.029508668929338455,\n",
       " -0.006066327914595604,\n",
       " -0.004881151486188173,\n",
       " 0.005539035424590111,\n",
       " 0.011659570969641209,\n",
       " -0.014941597357392311,\n",
       " -0.03167697414755821,\n",
       " -0.01277329120784998,\n",
       " 0.04119780659675598,\n",
       " -0.03993624821305275,\n",
       " -0.04218339920043945,\n",
       " 0.019258497282862663,\n",
       " -0.00883584562689066,\n",
       " -0.005159582011401653,\n",
       " 0.01812506467103958,\n",
       " 0.04210455343127251,\n",
       " 0.02264893800020218,\n",
       " -0.04797869175672531,\n",
       " 0.0486488938331604,\n",
       " 0.009762302972376347,\n",
       " -0.06465493142604828,\n",
       " 0.02625620923936367,\n",
       " 0.026473039761185646,\n",
       " -0.027438921853899956,\n",
       " -0.0071504805237054825,\n",
       " -0.008303624577820301,\n",
       " -0.002941996557638049,\n",
       " 0.009885502979159355,\n",
       " 0.03869440034031868,\n",
       " 0.010028413496911526,\n",
       " -0.03354960307478905,\n",
       " 0.01950489543378353,\n",
       " -0.029094718396663666,\n",
       " 0.03404239937663078,\n",
       " 0.04025163874030113,\n",
       " 0.04896428436040878,\n",
       " 0.021623920649290085,\n",
       " 0.02377251535654068,\n",
       " -0.02142680250108242,\n",
       " 0.0009283058461733162,\n",
       " -0.020894581452012062,\n",
       " 0.011630003340542316,\n",
       " -0.0051004462875425816,\n",
       " -0.026906702667474747,\n",
       " 0.020342649891972542,\n",
       " -0.035599637776613235,\n",
       " -0.036427535116672516,\n",
       " 0.028779329732060432,\n",
       " -0.011078070849180222,\n",
       " 0.0356193482875824,\n",
       " -0.01299997791647911,\n",
       " -0.00037514150608330965,\n",
       " -0.037511687725782394,\n",
       " -0.016922639682888985,\n",
       " -0.07147523760795593,\n",
       " 0.04033048450946808,\n",
       " -0.016755089163780212,\n",
       " -0.007919243536889553,\n",
       " -0.0032623144797980785,\n",
       " 0.07455029338598251,\n",
       " -0.016193300485610962,\n",
       " 0.015000732615590096,\n",
       " -0.020973429083824158,\n",
       " -0.039719417691230774,\n",
       " 0.02529032900929451,\n",
       " 0.005553819239139557,\n",
       " -0.06122506782412529,\n",
       " -0.01437980867922306,\n",
       " 0.00030691997380927205,\n",
       " 0.030356278643012047,\n",
       " 0.002998668234795332,\n",
       " -0.015582232736051083,\n",
       " 0.005016670562326908,\n",
       " -0.015818774700164795,\n",
       " -0.02115083672106266,\n",
       " 0.0353630930185318,\n",
       " 0.01920921728014946,\n",
       " -0.011245621368288994,\n",
       " 0.07612723857164383,\n",
       " 0.0039941174909472466,\n",
       " 0.0012215198948979378,\n",
       " 0.03660494089126587,\n",
       " -0.020894581452012062,\n",
       " -0.016952207311987877,\n",
       " 0.02099314145743847,\n",
       " 0.023733090609312057,\n",
       " 0.008934404700994492,\n",
       " 0.03416066989302635,\n",
       " -0.06272316724061966,\n",
       " 0.01725774258375168,\n",
       " 0.0383790098130703,\n",
       " -0.002261937130242586,\n",
       " 0.03479145094752312,\n",
       " -0.031696684658527374,\n",
       " -0.02458070032298565,\n",
       " -0.020618615671992302,\n",
       " 0.015513241291046143,\n",
       " -0.013709604740142822,\n",
       " -0.024245599284768105,\n",
       " 0.0417497381567955,\n",
       " 0.020500345155596733,\n",
       " -0.02694612555205822,\n",
       " -0.04218339920043945,\n",
       " -0.008338120765984058,\n",
       " 0.009166019037365913,\n",
       " 0.019140224903821945,\n",
       " 0.010762680321931839,\n",
       " -0.04340553656220436,\n",
       " -0.0014512863708660007,\n",
       " -0.002035250421613455,\n",
       " -0.0026315345894545317,\n",
       " 0.04841235280036926,\n",
       " 0.04474594444036484,\n",
       " 0.01796736940741539,\n",
       " 0.004755488596856594,\n",
       " -0.023673955351114273,\n",
       " 0.011580723337829113,\n",
       " 0.04439112916588783,\n",
       " 0.02389078587293625,\n",
       " 0.0314798541367054,\n",
       " -0.010476858355104923,\n",
       " 0.001039185095578432,\n",
       " -0.0010120812803506851,\n",
       " 0.005637594498693943,\n",
       " -0.023811938241124153,\n",
       " -0.019820284098386765,\n",
       " -0.014793758280575275,\n",
       " -0.039758842438459396,\n",
       " 0.0025157274212688208,\n",
       " -0.047190215438604355,\n",
       " -0.0051546539179980755,\n",
       " -0.10084592550992966,\n",
       " 0.007313103415071964,\n",
       " -0.04931909590959549,\n",
       " 0.0011506803566589952,\n",
       " 0.0019292992074042559,\n",
       " -0.016350995749235153,\n",
       " 0.010890807956457138,\n",
       " 0.018450310453772545,\n",
       " -0.010210748761892319,\n",
       " 0.019130369648337364,\n",
       " 0.004841728135943413,\n",
       " 0.03853670507669449,\n",
       " 0.002880397019907832,\n",
       " 0.0047012809664011,\n",
       " -0.03788621351122856,\n",
       " 0.016360851004719734,\n",
       " 0.03341161832213402,\n",
       " -0.013778597116470337,\n",
       " 0.031026482582092285,\n",
       " 0.022688360884785652,\n",
       " 0.021032564342021942,\n",
       " -0.04620462283492088,\n",
       " 0.03664436563849449,\n",
       " -0.04269590973854065,\n",
       " -0.01642984338104725,\n",
       " 0.01236919779330492,\n",
       " 0.019869564101099968,\n",
       " 0.04782099649310112,\n",
       " 0.0254480242729187,\n",
       " 0.0006313958438113332,\n",
       " -0.012280494906008244,\n",
       " -0.030494261533021927,\n",
       " 0.03236689046025276,\n",
       " 0.028404803946614265,\n",
       " -0.030159160494804382,\n",
       " -0.0017925481079146266,\n",
       " -0.003264778293669224,\n",
       " 0.049279674887657166,\n",
       " 0.04462767392396927,\n",
       " 0.04998930171132088,\n",
       " -0.01713947020471096,\n",
       " 0.00728846387937665,\n",
       " 0.020224377512931824,\n",
       " 0.08042442798614502,\n",
       " 0.017080334946513176,\n",
       " -0.02471868507564068,\n",
       " 0.0027054541278630495,\n",
       " 0.0012430797796696424,\n",
       " 0.02625620923936367,\n",
       " 0.04644116386771202,\n",
       " -0.030375991016626358,\n",
       " -0.014231969602406025,\n",
       " -0.00570658640936017,\n",
       " 0.0233782771974802,\n",
       " -0.025645142421126366,\n",
       " 0.025763412937521935,\n",
       " -0.026433616876602173,\n",
       " 0.002306288806721568,\n",
       " -0.026059091091156006,\n",
       " -0.04009394347667694,\n",
       " -0.0334707535803318,\n",
       " -0.024560989812016487,\n",
       " -0.0008630102965980768,\n",
       " 0.05937214940786362,\n",
       " 0.015158427879214287,\n",
       " -0.01823347993195057,\n",
       " -0.027872582897543907,\n",
       " 0.02239268459379673,\n",
       " -0.029390396550297737,\n",
       " -0.020480632781982422,\n",
       " -0.014054562896490097,\n",
       " -0.021860463544726372,\n",
       " -0.001125424518249929,\n",
       " -0.0771128311753273,\n",
       " 0.043720927089452744,\n",
       " 0.023181159049272537,\n",
       " 0.05704614892601967,\n",
       " -0.00438342709094286,\n",
       " -0.008421896025538445,\n",
       " -0.0550355389714241,\n",
       " -0.02278692089021206,\n",
       " 0.029390396550297737,\n",
       " -0.03287939727306366,\n",
       " 0.017642123624682426,\n",
       " 0.05440475791692734,\n",
       " -0.013108393177390099,\n",
       " -0.03508712723851204,\n",
       " 0.04005451872944832,\n",
       " -0.0021707697305828333,\n",
       " 0.006731603294610977,\n",
       " -0.014685343019664288,\n",
       " -0.047623876482248306,\n",
       " 0.04644116386771202,\n",
       " 0.0145769277587533,\n",
       " -0.007456014398485422,\n",
       " -0.03830016404390335,\n",
       " -0.03027743101119995,\n",
       " -0.026039378717541695,\n",
       " -0.009619392454624176,\n",
       " 0.009225155226886272,\n",
       " -0.021801328286528587,\n",
       " 0.07443201541900635,\n",
       " 0.024541277438402176,\n",
       " -0.04683540016412735,\n",
       " -0.014803613536059856,\n",
       " -0.00883584562689066,\n",
       " -0.003750183153897524,\n",
       " 0.03508712723851204,\n",
       " 0.010999223217368126,\n",
       " 0.013847588561475277,\n",
       " 0.03644724562764168,\n",
       " -0.009037892334163189,\n",
       " 0.03167697414755821,\n",
       " 0.0014044706476852298,\n",
       " 0.00305780372582376,\n",
       " -0.008264201693236828,\n",
       " 0.032977957278490067,\n",
       " 0.0467565543949604,\n",
       " 0.03313565254211426,\n",
       " -0.045534417033195496,\n",
       " -0.013019689358770847,\n",
       " 0.04395746812224388,\n",
       " -0.005386268254369497,\n",
       " 0.01548367366194725,\n",
       " -0.0186769962310791,\n",
       " 0.01327594369649887,\n",
       " 0.022984039038419724,\n",
       " 0.07549645751714706,\n",
       " 0.0032228906638920307,\n",
       " 0.024225886911153793,\n",
       " -0.024915803223848343,\n",
       " 0.0204412080347538,\n",
       " 0.010871095582842827,\n",
       " 0.07230313867330551,\n",
       " 0.013009834103286266,\n",
       " -0.06319625675678253,\n",
       " -0.04809696227312088,\n",
       " 0.04439112916588783,\n",
       " -0.014892317354679108,\n",
       " -0.03595444932579994,\n",
       " -0.003760039107874036,\n",
       " 0.025921108201146126,\n",
       " 0.018312327563762665,\n",
       " -0.0495162159204483,\n",
       " 0.0417497381567955,\n",
       " 0.02956780418753624,\n",
       " -0.02793171815574169,\n",
       " 0.005405980162322521,\n",
       " -0.06512801349163055,\n",
       " 0.014350241050124168,\n",
       " 0.01809549704194069,\n",
       " 0.012990121729671955,\n",
       " -0.02513263374567032,\n",
       " -0.003829030552878976,\n",
       " -0.03841843456029892,\n",
       " 0.017218317836523056,\n",
       " 0.006041687913239002,\n",
       " 0.01978086121380329,\n",
       " 0.028582211583852768,\n",
       " 0.003035628003999591,\n",
       " 0.02710382081568241,\n",
       " -0.004952607210725546,\n",
       " -0.0035407445393502712,\n",
       " 0.025112921372056007,\n",
       " -0.039463162422180176,\n",
       " -0.027675464749336243,\n",
       " -0.04596807807683945,\n",
       " -0.03218948096036911,\n",
       " -0.003784678876399994,\n",
       " 0.04573153704404831,\n",
       " 0.029075007885694504,\n",
       " -0.02071717567741871,\n",
       " -0.0026044307742267847,\n",
       " -0.0017629803624004126,\n",
       " 0.04052760452032089,\n",
       " 0.01700148731470108,\n",
       " 0.03250487148761749,\n",
       " -0.025743702426552773,\n",
       " -0.038359299302101135,\n",
       " 0.021308530122041702,\n",
       " -0.017513995990157127,\n",
       " -0.01642984338104725,\n",
       " -0.02448214218020439,\n",
       " 0.02172248065471649,\n",
       " -0.022865768522024155,\n",
       " -0.012832427397370338,\n",
       " -0.0309673473238945,\n",
       " -0.012901418842375278,\n",
       " 0.02942982129752636,\n",
       " 0.026295633986592293,\n",
       " 0.015256986953318119,\n",
       " 0.021328242495656013,\n",
       " 0.05870194733142853,\n",
       " -0.004356323275715113,\n",
       " -0.02402876876294613,\n",
       " 0.009954494424164295,\n",
       " -0.016764944419264793,\n",
       " -0.002914892742410302,\n",
       " -0.012763435021042824,\n",
       " -0.01299997791647911,\n",
       " 0.032150059938430786,\n",
       " 0.04060645028948784,\n",
       " 0.0009757375228218734,\n",
       " 0.004740704782307148,\n",
       " -0.01028959546238184,\n",
       " -0.03250487148761749,\n",
       " -0.004023685120046139,\n",
       " -0.04230167344212532,\n",
       " 0.011442740447819233,\n",
       " 0.02168305590748787,\n",
       " 0.034495770931243896,\n",
       " -0.003939909860491753,\n",
       " -0.03638811036944389,\n",
       " 0.03189380466938019,\n",
       " 0.05586343631148338,\n",
       " -0.0032499944791197777,\n",
       " 0.0008599302964285016,\n",
       " 0.0051004462875425816,\n",
       " 0.012526893056929111,\n",
       " 0.04076414555311203,\n",
       " 0.03274141624569893,\n",
       " 0.006342294160276651,\n",
       " 0.005770649760961533,\n",
       " 0.000769378908444196,\n",
       " 0.05609998106956482,\n",
       " -0.030868787318468094,\n",
       " 0.043720927089452744,\n",
       " -0.0004050173156429082,\n",
       " 0.01587790995836258,\n",
       " -0.016942352056503296,\n",
       " -0.003580168355256319,\n",
       " -0.006204310804605484,\n",
       " 0.05255184322595596,\n",
       " -0.024836955592036247,\n",
       " -0.0069237942807376385,\n",
       " 0.005134942010045052,\n",
       " -0.05223645269870758,\n",
       " -0.05318262428045273,\n",
       " -0.03467317670583725,\n",
       " -0.022471530362963676,\n",
       " 0.013295656070113182,\n",
       " 0.07391951233148575,\n",
       " 0.008200137875974178,\n",
       " -0.01879526674747467,\n",
       " -0.012812715023756027,\n",
       " 0.012172079645097256,\n",
       " -0.02942982129752636,\n",
       " 0.005435547791421413,\n",
       " 0.012142512015998363,\n",
       " -0.03956172242760658,\n",
       " -0.018420742824673653,\n",
       " 0.005430620163679123,\n",
       " 0.018430598080158234,\n",
       " 0.016666386276483536,\n",
       " 0.004765344318002462,\n",
       " 0.00023592643265146762,\n",
       " -0.0491614006459713,\n",
       " 0.013325223699212074,\n",
       " 0.012211503461003304,\n",
       " -0.021209971979260445,\n",
       " -0.008485959842801094,\n",
       " -0.008525383658707142,\n",
       " -0.011797553859651089,\n",
       " -0.02903558313846588,\n",
       " -0.03678234666585922,\n",
       " -0.028838464990258217,\n",
       " 0.015010588802397251,\n",
       " -0.010526138357818127,\n",
       " -0.04683540016412735,\n",
       " -0.039719417691230774,\n",
       " 0.02942982129752636,\n",
       " 0.016469266265630722,\n",
       " 0.008801349438726902,\n",
       " 0.023043176159262657,\n",
       " -0.0232008695602417,\n",
       " -0.021091699600219727,\n",
       " -0.01891353912651539,\n",
       " -1.726713526295498e-05,\n",
       " 0.03881267085671425,\n",
       " 0.02113112434744835,\n",
       " -0.007702413015067577,\n",
       " -0.0002157525741495192,\n",
       " 0.021880175918340683,\n",
       " 0.04584980756044388,\n",
       " -0.01162014715373516,\n",
       " 0.001049041049554944,\n",
       " 0.001605285331606865,\n",
       " 0.0472690612077713,\n",
       " -0.00967852771282196,\n",
       " 0.011896112933754921,\n",
       " 0.010595129802823067,\n",
       " -0.008914693258702755,\n",
       " -0.0034372571390122175,\n",
       " 0.002890252973884344,\n",
       " -0.05196048691868782,\n",
       " -0.0008014107006601989,\n",
       " 0.016498833894729614,\n",
       " -0.014655775390565395,\n",
       " -0.02099314145743847,\n",
       " -0.05759808421134949,\n",
       " 0.030218295753002167,\n",
       " 0.016331283375620842,\n",
       " 0.03871411085128784,\n",
       " -0.009693311527371407,\n",
       " -0.0189332515001297,\n",
       " 0.03414095938205719,\n",
       " -0.011137206107378006,\n",
       " -0.028286533430218697,\n",
       " -0.017632266506552696,\n",
       " -0.010447290726006031,\n",
       " -0.004494306165724993,\n",
       " 0.012477613054215908,\n",
       " 0.014438943937420845,\n",
       " -0.0062880865298211575,\n",
       " 0.018686851486563683,\n",
       " -0.03772851824760437,\n",
       " 0.014212258160114288,\n",
       " -0.006647828035056591,\n",
       " -0.029193278402090073,\n",
       " 0.0007170192548073828,\n",
       " -0.0019785789772868156,\n",
       " -0.011403316631913185,\n",
       " 0.009072387591004372,\n",
       " 0.0045805457048118114,\n",
       " 0.002493551466614008,\n",
       " -0.010930231772363186,\n",
       " 0.04573153704404831,\n",
       " 0.04328726604580879,\n",
       " 0.014369952492415905,\n",
       " 0.011639858596026897,\n",
       " 0.0021042420994490385,\n",
       " -0.005090590100735426,\n",
       " -0.01632142812013626,\n",
       " -0.025191769003868103,\n",
       " -0.05763750523328781,\n",
       " -0.03800448402762413,\n",
       " 0.015237275511026382,\n",
       " -0.0020697463769465685,\n",
       " 0.014941597357392311,\n",
       " -0.0035407445393502712,\n",
       " -0.03315536305308342,\n",
       " 0.0194950383156538,\n",
       " -0.015611800365149975,\n",
       " -0.008540167473256588,\n",
       " 0.003033163957297802,\n",
       " -0.014330528676509857,\n",
       " -0.016774801537394524,\n",
       " -0.012280494906008244,\n",
       " 0.004629825241863728,\n",
       " 0.02391049824655056,\n",
       " -0.07048964500427246,\n",
       " -0.020815733820199966,\n",
       " 0.015503385104238987,\n",
       " 0.0010311771184206009,\n",
       " 0.0033313059248030186,\n",
       " -0.0052236453630030155,\n",
       " -0.04060645028948784,\n",
       " -0.014399521052837372,\n",
       " -0.0046495371498167515,\n",
       " 0.014754334464669228,\n",
       " -0.004292259458452463,\n",
       " -0.007998091168701649,\n",
       " -0.006209238898009062,\n",
       " -0.01643969863653183,\n",
       " -0.026019668206572533,\n",
       " -0.023141734302043915,\n",
       " -0.0008679382735863328,\n",
       " 0.007929099723696709,\n",
       " 0.010664121247828007,\n",
       " 0.029094718396663666,\n",
       " -0.007860108278691769,\n",
       " -0.013719460926949978,\n",
       " 0.0323471762239933,\n",
       " -0.042617060244083405,\n",
       " 0.006672468036413193,\n",
       " 0.01632142812013626,\n",
       " -0.020618615671992302,\n",
       " 0.009796799160540104,\n",
       " 0.02115083672106266,\n",
       " -0.012852138839662075,\n",
       " -0.007968523539602757,\n",
       " 0.027478346601128578,\n",
       " 0.0026167507749050856,\n",
       " -0.019140224903821945,\n",
       " 0.029764922335743904,\n",
       " 0.00048078480176627636,\n",
       " 0.020953716710209846,\n",
       " 0.017592843621969223,\n",
       " -0.046638283878564835,\n",
       " -0.033786144107580185,\n",
       " -0.015178139321506023,\n",
       " -0.014113698154687881,\n",
       " -0.015542808920145035,\n",
       " -0.03893094137310982,\n",
       " 0.01071340125054121,\n",
       " -0.0403699092566967,\n",
       " -0.013216808438301086,\n",
       " 0.02282634563744068,\n",
       " 0.017376013100147247,\n",
       " -0.008264201693236828,\n",
       " -0.013965859077870846,\n",
       " -0.00017679082520771772,\n",
       " 0.0011001686798408628,\n",
       " 0.021190259605646133,\n",
       " -0.01810535229742527,\n",
       " 0.028542786836624146,\n",
       " 0.00466678524389863,\n",
       " -0.01235934253782034,\n",
       " -0.026473039761185646,\n",
       " 0.02430473454296589,\n",
       " -0.03384527936577797,\n",
       " 0.028266821056604385,\n",
       " -0.0017358765471726656,\n",
       " 0.0028064774814993143,\n",
       " 0.008180425502359867,\n",
       " 0.009116739965975285,\n",
       " -0.002223745221272111,\n",
       " -0.02653217688202858,\n",
       " -0.016893072053790092,\n",
       " -0.022313836961984634,\n",
       " 0.015187995508313179,\n",
       " 0.005080734379589558,\n",
       " 0.016360851004719734,\n",
       " 0.051605675369501114,\n",
       " -0.0010798408184200525,\n",
       " -0.016410131007432938,\n",
       " 0.051881641149520874,\n",
       " -0.0016804368933662772,\n",
       " 0.020066682249307632,\n",
       " 0.020283512771129608,\n",
       " -0.02513263374567032,\n",
       " 0.009121667593717575,\n",
       " -0.02958751656115055,\n",
       " 0.023417700082063675,\n",
       " -0.009372994303703308,\n",
       " 0.03591502457857132,\n",
       " -0.07045022398233414,\n",
       " -0.016656529158353806,\n",
       " -0.009663743898272514,\n",
       " 0.01698177494108677,\n",
       " -0.011501875706017017,\n",
       " 0.012674732133746147,\n",
       " -0.021071989089250565,\n",
       " -0.03128273785114288,\n",
       " -0.011423028074204922,\n",
       " 0.04849119856953621,\n",
       " 0.03993624821305275,\n",
       " -0.03386498987674713,\n",
       " 0.022077294066548347,\n",
       " -0.005386268254369497,\n",
       " -0.03175581991672516,\n",
       " 0.0021436659153550863,\n",
       " 0.015927189961075783,\n",
       " -0.00749543821439147,\n",
       " -0.0019477790920063853,\n",
       " 0.032150059938430786,\n",
       " 0.008057226426899433,\n",
       " -0.005519323516637087,\n",
       " 0.00890976469963789,\n",
       " -0.012457901611924171,\n",
       " -0.027419209480285645,\n",
       " 0.015493529848754406,\n",
       " -0.017888521775603294,\n",
       " -0.04868831858038902,\n",
       " -0.020953716710209846,\n",
       " 0.016104597598314285,\n",
       " 0.001971186837181449,\n",
       " 0.03733428195118904,\n",
       " 0.005366556346416473,\n",
       " -0.02696583792567253,\n",
       " -0.010358587838709354,\n",
       " 0.037393417209386826,\n",
       " 0.000630779832135886,\n",
       " -0.005617882590740919,\n",
       " -0.020658038556575775,\n",
       " -0.03299766778945923,\n",
       " -0.014813469722867012,\n",
       " -0.0026783503126353025,\n",
       " 0.00947155337780714,\n",
       " 0.03893094137310982,\n",
       " -0.009170947596430779,\n",
       " 0.03577704355120659,\n",
       " -0.022156141698360443,\n",
       " -0.007796044461429119,\n",
       " 0.02391049824655056,\n",
       " -0.013059113174676895,\n",
       " 0.010949943214654922,\n",
       " 0.03828044980764389,\n",
       " 0.0028582210652530193,\n",
       " -0.023122023791074753,\n",
       " 0.026039378717541695,\n",
       " 0.005785433575510979,\n",
       " 0.0009880574652925134,\n",
       " 0.021623920649290085,\n",
       " 0.029626939445734024,\n",
       " -0.03205149993300438,\n",
       " -0.04462767392396927,\n",
       " 0.007909387350082397,\n",
       " 0.0560605563223362,\n",
       " 0.007372239138931036,\n",
       " -0.003676263615489006,\n",
       " 0.005657306406646967,\n",
       " 0.0002525583258830011,\n",
       " -0.004748096689581871,\n",
       " 0.0013588869478553534,\n",
       " -0.025921108201146126,\n",
       " -0.008333193138241768,\n",
       " 0.036131855100393295,\n",
       " -0.028286533430218697,\n",
       " -0.004999422933906317,\n",
       " -0.022451819851994514,\n",
       " -0.0014857822097837925,\n",
       " -0.011275188997387886,\n",
       " -0.008352904580533504,\n",
       " 0.03824102506041527,\n",
       " -0.024915803223848343,\n",
       " -0.022353259846568108,\n",
       " 0.028582211583852768,\n",
       " -0.003969477489590645,\n",
       " 0.014843037351965904,\n",
       " 0.008796421810984612,\n",
       " 0.005080734379589558,\n",
       " -0.04253821447491646,\n",
       " 0.014330528676509857,\n",
       " -0.014793758280575275,\n",
       " 0.017789961770176888,\n",
       " 0.0003806854656431824,\n",
       " 0.013177384622395039,\n",
       " -0.007569357752799988,\n",
       " 0.03512655198574066,\n",
       " -0.04289302974939346,\n",
       " 0.0072194719687104225,\n",
       " 0.029902905225753784,\n",
       " 0.01272401213645935,\n",
       " 0.033234212547540665,\n",
       " -0.0038733824621886015,\n",
       " 0.040133364498615265,\n",
       " -0.008259273134171963,\n",
       " -0.021170547232031822,\n",
       " 0.04975275695323944,\n",
       " -0.027990855276584625,\n",
       " 0.0215647853910923,\n",
       " -0.05125086009502411,\n",
       " -0.020796021446585655,\n",
       " 0.013798308558762074,\n",
       " -0.006293014157563448,\n",
       " -0.010683833621442318,\n",
       " 0.010427579283714294,\n",
       " -0.0011987281031906605,\n",
       " -0.01837146282196045,\n",
       " -0.013896867632865906,\n",
       " 0.030021177604794502,\n",
       " -0.04104011133313179,\n",
       " -0.021229682490229607,\n",
       " -0.024659547954797745,\n",
       " 0.025901395827531815,\n",
       " -0.02623649872839451,\n",
       " 0.025191769003868103,\n",
       " 0.03250487148761749,\n",
       " -0.0168635044246912,\n",
       " -0.019307775422930717,\n",
       " 0.04072472080588341,\n",
       " 0.030592821538448334,\n",
       " 0.015079580247402191,\n",
       " -0.015572376549243927,\n",
       " 0.02375280298292637,\n",
       " -0.045100755989551544,\n",
       " -0.021091699600219727,\n",
       " -0.03313565254211426,\n",
       " -0.014448800124228,\n",
       " -0.00752993393689394,\n",
       " 0.014734622091054916,\n",
       " 0.003612200031057,\n",
       " -0.028720194473862648,\n",
       " 0.01188625767827034,\n",
       " -0.010545849800109863,\n",
       " -0.006243734620511532,\n",
       " 0.022353259846568108,\n",
       " -0.005785433575510979,\n",
       " 0.014675486832857132,\n",
       " -0.0017284845234826207,\n",
       " -0.00231614476069808,\n",
       " 0.01587790995836258,\n",
       " 0.01797722466289997,\n",
       " -0.0014463583938777447,\n",
       " -0.0015892694937065244,\n",
       " 0.012073519639670849,\n",
       " -0.03634868562221527,\n",
       " -0.03715687245130539,\n",
       " 0.020835446193814278,\n",
       " -0.0020315544679760933,\n",
       " 0.04115838184952736,\n",
       " -0.012132655829191208,\n",
       " 0.0014870141167193651,\n",
       " -0.025901395827531815,\n",
       " 0.03843814507126808,\n",
       " 0.0035407445393502712,\n",
       " -0.002322304528206587,\n",
       " 0.0027227019891142845,\n",
       " 0.014813469722867012,\n",
       " -0.0071849762462079525,\n",
       " 0.02475810796022415,\n",
       " -0.026591312140226364,\n",
       " 0.020007546991109848,\n",
       " -0.005780505947768688,\n",
       " -0.010240316390991211,\n",
       " 0.015937047079205513,\n",
       " -0.03250487148761749,\n",
       " 0.009688383899629116,\n",
       " 0.010831672698259354,\n",
       " 0.002407312160357833,\n",
       " 0.0034101533237844706,\n",
       " 0.02375280298292637,\n",
       " -0.05653364211320877,\n",
       " -0.01574978418648243,\n",
       " -0.01656782627105713,\n",
       " 0.011285045184195042,\n",
       " 0.035579923540353775,\n",
       " 0.01643969863653183,\n",
       " -0.014921884983778,\n",
       " 0.0011488323798403144,\n",
       " 0.011009079404175282,\n",
       " 0.022018158808350563,\n",
       " 0.05385282635688782,\n",
       " 0.0204412080347538,\n",
       " 0.008673222735524178,\n",
       " 0.031420718878507614,\n",
       " -0.002147361868992448,\n",
       " -0.002444271696731448,\n",
       " 0.006169815082103014,\n",
       " -0.009821439161896706,\n",
       " -0.018174342811107635,\n",
       " -0.020658038556575775,\n",
       " -0.009860862977802753,\n",
       " -0.006090967450290918,\n",
       " 0.0233782771974802,\n",
       " 0.043050721287727356,\n",
       " 0.0323471762239933,\n",
       " -0.03041541390120983,\n",
       " 0.004583009518682957,\n",
       " 0.007598925847560167,\n",
       " 0.019721725955605507,\n",
       " 0.016262292861938477,\n",
       " 0.04021221399307251,\n",
       " 0.009284290485084057,\n",
       " 0.04356323182582855,\n",
       " 0.040961265563964844,\n",
       " 0.004122244659811258,\n",
       " -0.047032520174980164,\n",
       " 0.0009510976960882545,\n",
       " 0.03410153463482857,\n",
       " -0.02266865037381649,\n",
       " 0.06962232291698456,\n",
       " -0.01946547068655491,\n",
       " -0.0031440432649105787,\n",
       " -0.0013687429018318653,\n",
       " -0.004287331830710173,\n",
       " 0.017316877841949463,\n",
       " -0.008328264579176903,\n",
       " 0.00954054482281208,\n",
       " -0.02609851583838463,\n",
       " -0.030060600489377975,\n",
       " -0.005622810684144497,\n",
       " -0.02927212603390217,\n",
       " 0.0401136539876461,\n",
       " -0.03621070459485054,\n",
       " 0.015670936554670334,\n",
       " -0.005033918656408787,\n",
       " 0.02763604186475277,\n",
       " 0.013965859077870846,\n",
       " -0.012408621609210968,\n",
       " 0.05069892853498459,\n",
       " 0.006657683756202459,\n",
       " 0.007835468277335167,\n",
       " -0.014478367753326893,\n",
       " -0.004479522351175547,\n",
       " -0.04699309542775154,\n",
       " 0.03358902409672737,\n",
       " 0.016626961529254913,\n",
       " 0.0010311771184206009,\n",
       " -0.02501436322927475,\n",
       " 0.013364647515118122,\n",
       " 0.02696583792567253,\n",
       " -0.028128838166594505,\n",
       " -0.005405980162322521,\n",
       " 0.003146507078781724,\n",
       " -0.026157651096582413,\n",
       " 0.013847588561475277,\n",
       " 0.04935852065682411,\n",
       " 0.027734600007534027,\n",
       " 0.012536749243736267,\n",
       " 0.017898377031087875,\n",
       " -0.019169792532920837,\n",
       " 0.057992320507764816,\n",
       " -0.008412039838731289,\n",
       " 0.02073688618838787,\n",
       " 0.03934489190578461,\n",
       " -0.02599995583295822,\n",
       " -0.011817265301942825,\n",
       " -0.02653217688202858,\n",
       " -0.008278985507786274,\n",
       " 0.0004278091655578464,\n",
       " 0.049121979624032974,\n",
       " -0.00960460864007473,\n",
       " -0.012487469241023064,\n",
       " -0.013887012377381325,\n",
       " 0.04478536918759346,\n",
       " -0.00604661600664258,\n",
       " 0.043720927089452744,\n",
       " 0.003166218986734748,\n",
       " 0.02182103879749775,\n",
       " 0.03437750041484833,\n",
       " -0.03274141624569893,\n",
       " 0.018144775182008743,\n",
       " -0.002922284649685025,\n",
       " 0.021229682490229607,\n",
       " 0.016932494938373566,\n",
       " -0.01499087642878294,\n",
       " 0.008623942732810974,\n",
       " 0.06954347342252731,\n",
       " 0.017642123624682426,\n",
       " -0.009077316150069237,\n",
       " -0.006997713819146156,\n",
       " -0.00782068446278572,\n",
       " 0.023713378235697746,\n",
       " -0.04060645028948784,\n",
       " 0.0015978934243321419,\n",
       " -0.01656782627105713,\n",
       " -0.019376767799258232,\n",
       " 0.02554658241569996,\n",
       " 0.03374671936035156,\n",
       " 0.011472308076918125,\n",
       " -0.005770649760961533,\n",
       " 0.021939311176538467,\n",
       " -0.05404994636774063,\n",
       " 0.032406315207481384,\n",
       " -0.026709582656621933,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "get_embedding(\"Hola! ¿Qué tal estas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>I've had a Jam Man for some time, which as a t...</td>\n",
       "      <td>[-0.03681444376707077, 0.001284798257984221, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7947</th>\n",
       "      <td>Very close to the sound of an SM-58. Not quite...</td>\n",
       "      <td>[-0.027976877987384796, -0.02220250852406025, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>The sheets seem to work fine to polish the fre...</td>\n",
       "      <td>[0.04104297235608101, 0.020026810467243195, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>Although I never gigged with it I think this w...</td>\n",
       "      <td>[-0.04462393373250961, -0.03721298649907112, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>This is a good product. These work very well a...</td>\n",
       "      <td>[0.014727573841810226, -0.027694379910826683, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>I bought it to use with my Boss ME-70. I use t...</td>\n",
       "      <td>[-0.003695300780236721, -0.016964789479970932,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7119</th>\n",
       "      <td>As soon as put it on my guitar, I enjoyed the ...</td>\n",
       "      <td>[0.015628434717655182, -0.0201640073210001, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>The Martin MSP4200 SP Phosphor Bronze Acoustic...</td>\n",
       "      <td>[0.011762645095586777, -0.04375704005360603, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>D'Addario Are The Best Strings That I Have Tri...</td>\n",
       "      <td>[0.029030298814177513, -0.035048775374889374, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>It does the job.  Easy to get on and off.  See...</td>\n",
       "      <td>[-0.012856115587055683, -0.03493538871407509, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  \\\n",
       "10009  I've had a Jam Man for some time, which as a t...   \n",
       "7947   Very close to the sound of an SM-58. Not quite...   \n",
       "4357   The sheets seem to work fine to polish the fre...   \n",
       "6258   Although I never gigged with it I think this w...   \n",
       "10031  This is a good product. These work very well a...   \n",
       "5250   I bought it to use with my Boss ME-70. I use t...   \n",
       "7119   As soon as put it on my guitar, I enjoyed the ...   \n",
       "763    The Martin MSP4200 SP Phosphor Bronze Acoustic...   \n",
       "2136   D'Addario Are The Best Strings That I Have Tri...   \n",
       "9426   It does the job.  Easy to get on and off.  See...   \n",
       "\n",
       "                                               embedding  \n",
       "10009  [-0.03681444376707077, 0.001284798257984221, -...  \n",
       "7947   [-0.027976877987384796, -0.02220250852406025, ...  \n",
       "4357   [0.04104297235608101, 0.020026810467243195, -0...  \n",
       "6258   [-0.04462393373250961, -0.03721298649907112, -...  \n",
       "10031  [0.014727573841810226, -0.027694379910826683, ...  \n",
       "5250   [-0.003695300780236721, -0.016964789479970932,...  \n",
       "7119   [0.015628434717655182, -0.0201640073210001, -0...  \n",
       "763    [0.011762645095586777, -0.04375704005360603, -...  \n",
       "2136   [0.029030298814177513, -0.035048775374889374, ...  \n",
       "9426   [-0.012856115587055683, -0.03493538871407509, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = review_df.sample(100)\n",
    "review_df[\"embedding\"] = review_df[\"reviewText\"].astype(str).apply(get_embedding)\n",
    "\n",
    "# Make the index start from 0\n",
    "review_df.reset_index(drop=True)\n",
    "\n",
    "review_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un nivel en el que habitualmente no solemos trabajar, pero para poder ajustar los modelos o encontrar documentos/textos relevantes para nuestra búsqueda, será importante conocer que existe esta opción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
