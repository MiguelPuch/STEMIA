{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a615e57",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Para que sea sencillo de realizar por todos, vamos a ver si podemos encontrar un modelo del tipo \"Instruct\" (que reciba preguntas y las responda) y configurarlo para que pueda ayudarnos con preguntas de codificación.\n",
    "\n",
    "Queremos poder plantearle retos y que nos devuelva código Python que seamos capaces de ejecutar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c004df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = ... # Vuestro modelo elegido\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b303f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "\n",
    "SISTEMA = \"...\" # Introducir las instrucciones de vuestro asistente\n",
    "CONSULTA=\"Crea un programa capaz de ejecutar operaciones matemáticas complejas que incluyan sumar, restar, dividir y multiplicar operaciones de forma arbitraria.\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(SISTEMA),\n",
    "        UserMessage(CONSULTA),\n",
    "    ],\n",
    "    # Podéis probar a cambiar los parámetros del modelo\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    max_tokens=1000,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
